{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do some imports\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and process data\n",
    "train = pd.read_json(\"../train.json\")\n",
    "test = pd.read_json(\"../test.json\")\n",
    "# Fill 'na' angles with zero\n",
    "train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "test.inc_angle = test.inc_angle.replace('na', 0)\n",
    "test.inc_angle = test.inc_angle.astype(float).fillna(0.0)\n",
    "\n",
    "# Process data into images\n",
    "def process_images(df):\n",
    "    X_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_1\"]])\n",
    "    X_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_2\"]])\n",
    "    # Merge bands and add another band as the mean of Band 1 and Band 2 (useful for the ImageDataGenerator later)\n",
    "    imgs = np.concatenate([X_band1[:, :, :, np.newaxis]\n",
    "                            , X_band2[:, :, :, np.newaxis]\n",
    "                            ,((X_band1+X_band2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "    return imgs\n",
    "\n",
    "X_train = process_images(train)\n",
    "X_test = process_images(test)\n",
    "\n",
    "X_angle_train = np.array(train.inc_angle)\n",
    "X_angle_test = np.array(test.inc_angle)\n",
    "y_train = np.array(train[\"is_iceberg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split, 75% of data used in training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, X_angle_train, X_angle_valid, y_train, y_valid = train_test_split(X_train,\n",
    "                                    X_angle_train, y_train, random_state=666, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, concatenate, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Dropout, GlobalMaxPooling2D\n",
    "\n",
    "def simple_cnn():\n",
    "    pic_input = Input(shape=(75, 75, 3))\n",
    "    ang_input = Input(shape=(1,))\n",
    "\n",
    "    cnn = BatchNormalization()(pic_input)\n",
    "    for i in range(4):\n",
    "        cnn = Conv2D(8*2**i, kernel_size = (3,3), activation='relu')(cnn)\n",
    "        cnn = MaxPooling2D((2,2))(cnn)\n",
    "    cnn = GlobalMaxPooling2D()(cnn)\n",
    "    cnn = concatenate([cnn,ang_input])\n",
    "    cnn = Dense(32,activation='relu')(cnn)\n",
    "    cnn = Dense(1, activation = 'sigmoid')(cnn)\n",
    "\n",
    "    simple_cnn = Model(inputs=[pic_input,ang_input],outputs=cnn)\n",
    "\n",
    "    simple_cnn.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return simple_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size=64\n",
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,\n",
    "                         zoom_range = 0.1,\n",
    "                         rotation_range = 40)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=666)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=666)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "gen_flow = gen_flow_for_two_inputs(X_train, X_angle_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/18 [==============================] - 3s - loss: 1.9658 - acc: 0.4170 - val_loss: 1.9126 - val_acc: 0.5112\n",
      "Epoch 2/20\n",
      "19/18 [==============================] - 1s - loss: 0.6687 - acc: 0.5959 - val_loss: 7.8782 - val_acc: 0.5112\n",
      "Epoch 3/20\n",
      "19/18 [==============================] - 1s - loss: 0.5754 - acc: 0.6833 - val_loss: 7.6412 - val_acc: 0.5112\n",
      "Epoch 4/20\n",
      "19/18 [==============================] - 1s - loss: 0.5504 - acc: 0.6923 - val_loss: 3.4913 - val_acc: 0.5112\n",
      "Epoch 5/20\n",
      "19/18 [==============================] - 1s - loss: 0.4858 - acc: 0.7512 - val_loss: 2.9277 - val_acc: 0.5112\n",
      "Epoch 6/20\n",
      "19/18 [==============================] - 1s - loss: 0.4701 - acc: 0.7652 - val_loss: 2.1087 - val_acc: 0.5137\n",
      "Epoch 7/20\n",
      "19/18 [==============================] - 1s - loss: 0.4732 - acc: 0.7717 - val_loss: 1.3796 - val_acc: 0.5337\n",
      "Epoch 8/20\n",
      "19/18 [==============================] - 1s - loss: 0.4691 - acc: 0.7652 - val_loss: 0.8455 - val_acc: 0.5586\n",
      "Epoch 9/20\n",
      "19/18 [==============================] - 1s - loss: 0.4542 - acc: 0.7781 - val_loss: 0.9655 - val_acc: 0.5337\n",
      "Epoch 10/20\n",
      "19/18 [==============================] - 1s - loss: 0.4465 - acc: 0.7888 - val_loss: 0.7543 - val_acc: 0.5885\n",
      "Epoch 11/20\n",
      "19/18 [==============================] - 1s - loss: 0.4278 - acc: 0.8040 - val_loss: 0.5354 - val_acc: 0.7282\n",
      "Epoch 12/20\n",
      "19/18 [==============================] - 1s - loss: 0.4080 - acc: 0.8078 - val_loss: 0.4375 - val_acc: 0.7930\n",
      "Epoch 13/20\n",
      "19/18 [==============================] - 1s - loss: 0.4133 - acc: 0.8063 - val_loss: 0.4048 - val_acc: 0.7980\n",
      "Epoch 14/20\n",
      "19/18 [==============================] - 1s - loss: 0.4018 - acc: 0.8094 - val_loss: 0.4899 - val_acc: 0.7606\n",
      "Epoch 15/20\n",
      "19/18 [==============================] - 1s - loss: 0.3932 - acc: 0.8106 - val_loss: 0.3927 - val_acc: 0.7980\n",
      "Epoch 16/20\n",
      "19/18 [==============================] - 1s - loss: 0.3901 - acc: 0.8184 - val_loss: 0.3914 - val_acc: 0.8005\n",
      "Epoch 17/20\n",
      "19/18 [==============================] - 1s - loss: 0.3485 - acc: 0.8414 - val_loss: 0.3666 - val_acc: 0.8155\n",
      "Epoch 18/20\n",
      "19/18 [==============================] - 1s - loss: 0.3465 - acc: 0.8503 - val_loss: 0.3683 - val_acc: 0.8130\n",
      "Epoch 19/20\n",
      "19/18 [==============================] - 1s - loss: 0.3331 - acc: 0.8561 - val_loss: 0.3258 - val_acc: 0.8354\n",
      "Epoch 20/20\n",
      "19/18 [==============================] - 1s - loss: 0.3314 - acc: 0.8359 - val_loss: 0.4090 - val_acc: 0.7980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62d018d4a8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "model = simple_cnn()\n",
    "\n",
    "# Fit the model using our generator defined above\n",
    "model.fit_generator(gen_flow, validation_data=([X_valid, X_angle_valid], y_valid),\n",
    "                    steps_per_epoch= (len(X_train)/batch_size), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "test_predictions = model.predict([X_test,X_angle_test])\n",
    "\n",
    "# Create .csv\n",
    "pred_df = test[['id']].copy()\n",
    "pred_df['is_iceberg'] = test_predictions\n",
    "pred_df.to_csv('predictions1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
