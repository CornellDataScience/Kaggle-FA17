{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.util.montage import montage2d\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (1604, 5) loaded (1604, 75, 75, 2)\n",
      "testing (8424, 4) loaded (8424, 75, 75, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>[-20.983963, -18.986147, -18.636415, -21.13527...</td>\n",
       "      <td>[-28.293722, -27.309444, -26.149689, -26.14977...</td>\n",
       "      <td>a47b7dee</td>\n",
       "      <td>32.2297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>[-22.191774, -21.276672, -24.626541, -28.40771...</td>\n",
       "      <td>[-25.428791, -26.312912, -25.713694, -24.88588...</td>\n",
       "      <td>93beaaaa</td>\n",
       "      <td>41.8704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>[-25.652521, -27.236193, -21.93988, -20.547207...</td>\n",
       "      <td>[-34.367096, -32.27243, -31.112637, -33.611458...</td>\n",
       "      <td>2b88818c</td>\n",
       "      <td>42.5591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                band_1  \\\n",
       "723  [-20.983963, -18.986147, -18.636415, -21.13527...   \n",
       "791  [-22.191774, -21.276672, -24.626541, -28.40771...   \n",
       "111  [-25.652521, -27.236193, -21.93988, -20.547207...   \n",
       "\n",
       "                                                band_2        id inc_angle  \\\n",
       "723  [-28.293722, -27.309444, -26.149689, -26.14977...  a47b7dee   32.2297   \n",
       "791  [-25.428791, -26.312912, -25.713694, -24.88588...  93beaaaa   41.8704   \n",
       "111  [-34.367096, -32.27243, -31.112637, -33.611458...  2b88818c   42.5591   \n",
       "\n",
       "     is_iceberg  \n",
       "723           1  \n",
       "791           0  \n",
       "111           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_format(in_path):\n",
    "    out_df = pd.read_json(in_path)\n",
    "    out_images = out_df.apply(lambda c_row: [np.stack([c_row['band_1'],c_row['band_2']], -1).reshape((75,75,2))],1)\n",
    "    out_images = np.stack(out_images).squeeze()\n",
    "    return out_df, out_images\n",
    "train_df, train_images = load_and_format('../train.json')\n",
    "print('training', train_df.shape, 'loaded', train_images.shape)\n",
    "test_df, test_images = load_and_format('../test.json')\n",
    "print('testing', test_df.shape, 'loaded', test_images.shape)\n",
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (802, 75, 75, 2) (802, 2)\n",
      "Validation (802, 75, 75, 2) (802, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images,\n",
    "                                                   to_categorical(train_df['is_iceberg']),\n",
    "                                                    random_state = 2017,\n",
    "                                                    test_size = 0.5\n",
    "                                                   )\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Validation', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 75, 75, 2)         8         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 73, 73, 8)         152       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 36, 36, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 34, 34, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 17, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 25,002\n",
      "Trainable params: 24,998\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, BatchNormalization, Dropout, MaxPooling2D, GlobalMaxPooling2D, Dense\n",
    "simple_cnn = Sequential()\n",
    "simple_cnn.add(BatchNormalization(input_shape = (75, 75, 2)))\n",
    "for i in range(4):\n",
    "    simple_cnn.add(Conv2D(8*2**i, kernel_size = (3,3)))\n",
    "    simple_cnn.add(MaxPooling2D((2,2)))\n",
    "simple_cnn.add(GlobalMaxPooling2D())\n",
    "simple_cnn.add(Dropout(0.5))\n",
    "simple_cnn.add(Dense(8))\n",
    "simple_cnn.add(Dense(2, activation = 'softmax'))\n",
    "simple_cnn.compile(optimizer='sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "simple_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 802 samples, validate on 802 samples\n",
      "Epoch 1/100\n",
      "802/802 [==============================] - 0s - loss: 0.7157 - acc: 0.5673 - val_loss: 0.9253 - val_acc: 0.4788\n",
      "Epoch 2/100\n",
      "802/802 [==============================] - 0s - loss: 0.6719 - acc: 0.5898 - val_loss: 1.5169 - val_acc: 0.4788\n",
      "Epoch 3/100\n",
      "802/802 [==============================] - 0s - loss: 0.6225 - acc: 0.6322 - val_loss: 1.2257 - val_acc: 0.5212\n",
      "Epoch 4/100\n",
      "802/802 [==============================] - 0s - loss: 0.6123 - acc: 0.6322 - val_loss: 0.9878 - val_acc: 0.5698\n",
      "Epoch 5/100\n",
      "802/802 [==============================] - 0s - loss: 0.5961 - acc: 0.6334 - val_loss: 0.6972 - val_acc: 0.6746\n",
      "Epoch 6/100\n",
      "802/802 [==============================] - 0s - loss: 0.5760 - acc: 0.6671 - val_loss: 0.7762 - val_acc: 0.6035\n",
      "Epoch 7/100\n",
      "802/802 [==============================] - 0s - loss: 0.5587 - acc: 0.6820 - val_loss: 0.6380 - val_acc: 0.6496\n",
      "Epoch 8/100\n",
      "802/802 [==============================] - 0s - loss: 0.5257 - acc: 0.7195 - val_loss: 0.6484 - val_acc: 0.6895\n",
      "Epoch 9/100\n",
      "802/802 [==============================] - 0s - loss: 0.5352 - acc: 0.7082 - val_loss: 0.6013 - val_acc: 0.6845\n",
      "Epoch 10/100\n",
      "802/802 [==============================] - 0s - loss: 0.5155 - acc: 0.7382 - val_loss: 0.5505 - val_acc: 0.6733\n",
      "Epoch 11/100\n",
      "802/802 [==============================] - 0s - loss: 0.4984 - acc: 0.7269 - val_loss: 0.6605 - val_acc: 0.5723\n",
      "Epoch 12/100\n",
      "802/802 [==============================] - 0s - loss: 0.4940 - acc: 0.7456 - val_loss: 0.5991 - val_acc: 0.6471\n",
      "Epoch 13/100\n",
      "802/802 [==============================] - 0s - loss: 0.4770 - acc: 0.7544 - val_loss: 0.4898 - val_acc: 0.7519\n",
      "Epoch 14/100\n",
      "802/802 [==============================] - 0s - loss: 0.4425 - acc: 0.7805 - val_loss: 0.4615 - val_acc: 0.7743\n",
      "Epoch 15/100\n",
      "802/802 [==============================] - 0s - loss: 0.4356 - acc: 0.7930 - val_loss: 0.4949 - val_acc: 0.6908\n",
      "Epoch 16/100\n",
      "802/802 [==============================] - 0s - loss: 0.4341 - acc: 0.7918 - val_loss: 0.6091 - val_acc: 0.6721\n",
      "Epoch 17/100\n",
      "802/802 [==============================] - 0s - loss: 0.4329 - acc: 0.8005 - val_loss: 0.5861 - val_acc: 0.6209\n",
      "Epoch 18/100\n",
      "802/802 [==============================] - 0s - loss: 0.4119 - acc: 0.8030 - val_loss: 1.6989 - val_acc: 0.4788\n",
      "Epoch 19/100\n",
      "802/802 [==============================] - 0s - loss: 0.4995 - acc: 0.7855 - val_loss: 0.4340 - val_acc: 0.7868\n",
      "Epoch 20/100\n",
      "802/802 [==============================] - 0s - loss: 0.3963 - acc: 0.8167 - val_loss: 0.4516 - val_acc: 0.7756\n",
      "Epoch 21/100\n",
      "802/802 [==============================] - 0s - loss: 0.4033 - acc: 0.8155 - val_loss: 1.1828 - val_acc: 0.5212\n",
      "Epoch 22/100\n",
      "802/802 [==============================] - 0s - loss: 0.4314 - acc: 0.7868 - val_loss: 0.4258 - val_acc: 0.7943\n",
      "Epoch 23/100\n",
      "802/802 [==============================] - 0s - loss: 0.3654 - acc: 0.8329 - val_loss: 0.3771 - val_acc: 0.8292\n",
      "Epoch 24/100\n",
      "802/802 [==============================] - 0s - loss: 0.3642 - acc: 0.8329 - val_loss: 0.4053 - val_acc: 0.7918\n",
      "Epoch 25/100\n",
      "802/802 [==============================] - 0s - loss: 0.3436 - acc: 0.8491 - val_loss: 0.3970 - val_acc: 0.8192\n",
      "Epoch 26/100\n",
      "802/802 [==============================] - 0s - loss: 0.3324 - acc: 0.8479 - val_loss: 0.8967 - val_acc: 0.6172\n",
      "Epoch 27/100\n",
      "802/802 [==============================] - 0s - loss: 0.3841 - acc: 0.8392 - val_loss: 1.1181 - val_acc: 0.5299\n",
      "Epoch 28/100\n",
      "802/802 [==============================] - 0s - loss: 0.3667 - acc: 0.8254 - val_loss: 0.4440 - val_acc: 0.7855\n",
      "Epoch 29/100\n",
      "802/802 [==============================] - 0s - loss: 0.3283 - acc: 0.8541 - val_loss: 0.6084 - val_acc: 0.7120\n",
      "Epoch 30/100\n",
      "802/802 [==============================] - 0s - loss: 0.3274 - acc: 0.8441 - val_loss: 0.4727 - val_acc: 0.7556\n",
      "Epoch 31/100\n",
      "802/802 [==============================] - 0s - loss: 0.3358 - acc: 0.8416 - val_loss: 0.3657 - val_acc: 0.8304\n",
      "Epoch 32/100\n",
      "802/802 [==============================] - 0s - loss: 0.2881 - acc: 0.8791 - val_loss: 0.3553 - val_acc: 0.8354\n",
      "Epoch 33/100\n",
      "802/802 [==============================] - 0s - loss: 0.2980 - acc: 0.8628 - val_loss: 0.8476 - val_acc: 0.7132\n",
      "Epoch 34/100\n",
      "802/802 [==============================] - 0s - loss: 0.3305 - acc: 0.8429 - val_loss: 2.5240 - val_acc: 0.5162\n",
      "Epoch 35/100\n",
      "802/802 [==============================] - 0s - loss: 0.3711 - acc: 0.8641 - val_loss: 0.4260 - val_acc: 0.7905\n",
      "Epoch 36/100\n",
      "802/802 [==============================] - 0s - loss: 0.2905 - acc: 0.8753 - val_loss: 1.1259 - val_acc: 0.5424\n",
      "Epoch 37/100\n",
      "802/802 [==============================] - 0s - loss: 0.3014 - acc: 0.8803 - val_loss: 0.3766 - val_acc: 0.8292\n",
      "Epoch 38/100\n",
      "802/802 [==============================] - 0s - loss: 0.2601 - acc: 0.8878 - val_loss: 0.5749 - val_acc: 0.7631\n",
      "Epoch 39/100\n",
      "802/802 [==============================] - 0s - loss: 0.2694 - acc: 0.8803 - val_loss: 1.6442 - val_acc: 0.5349\n",
      "Epoch 40/100\n",
      "802/802 [==============================] - 0s - loss: 0.4057 - acc: 0.8404 - val_loss: 0.3586 - val_acc: 0.8329\n",
      "Epoch 41/100\n",
      "802/802 [==============================] - 0s - loss: 0.2545 - acc: 0.8878 - val_loss: 0.4305 - val_acc: 0.7980\n",
      "Epoch 42/100\n",
      "802/802 [==============================] - 0s - loss: 0.2341 - acc: 0.9127 - val_loss: 0.3791 - val_acc: 0.8080\n",
      "Epoch 43/100\n",
      "802/802 [==============================] - 0s - loss: 0.1979 - acc: 0.9289 - val_loss: 0.3616 - val_acc: 0.8329\n",
      "Epoch 44/100\n",
      "802/802 [==============================] - 0s - loss: 0.2356 - acc: 0.9077 - val_loss: 0.3974 - val_acc: 0.8292\n",
      "Epoch 45/100\n",
      "802/802 [==============================] - 0s - loss: 0.2321 - acc: 0.9052 - val_loss: 0.3512 - val_acc: 0.8454\n",
      "Epoch 46/100\n",
      "802/802 [==============================] - 0s - loss: 0.2327 - acc: 0.9152 - val_loss: 0.3778 - val_acc: 0.8317\n",
      "Epoch 47/100\n",
      "802/802 [==============================] - 0s - loss: 0.1982 - acc: 0.9227 - val_loss: 0.6165 - val_acc: 0.7282\n",
      "Epoch 48/100\n",
      "802/802 [==============================] - 0s - loss: 0.2292 - acc: 0.9102 - val_loss: 0.3144 - val_acc: 0.8616\n",
      "Epoch 49/100\n",
      "802/802 [==============================] - 0s - loss: 0.2071 - acc: 0.9202 - val_loss: 2.1721 - val_acc: 0.5499\n",
      "Epoch 50/100\n",
      "802/802 [==============================] - 0s - loss: 0.3347 - acc: 0.8990 - val_loss: 0.4939 - val_acc: 0.7631\n",
      "Epoch 51/100\n",
      "802/802 [==============================] - 0s - loss: 0.2117 - acc: 0.9190 - val_loss: 0.3343 - val_acc: 0.8504\n",
      "Epoch 52/100\n",
      "802/802 [==============================] - 0s - loss: 0.1881 - acc: 0.9239 - val_loss: 0.4556 - val_acc: 0.7993\n",
      "Epoch 53/100\n",
      "802/802 [==============================] - 0s - loss: 0.1940 - acc: 0.9202 - val_loss: 0.3875 - val_acc: 0.8292\n",
      "Epoch 54/100\n",
      "802/802 [==============================] - 0s - loss: 0.1822 - acc: 0.9289 - val_loss: 0.7441 - val_acc: 0.7481\n",
      "Epoch 55/100\n",
      "802/802 [==============================] - 0s - loss: 0.1752 - acc: 0.9314 - val_loss: 0.5612 - val_acc: 0.7656\n",
      "Epoch 56/100\n",
      "802/802 [==============================] - 0s - loss: 0.2549 - acc: 0.9052 - val_loss: 0.3482 - val_acc: 0.8479\n",
      "Epoch 57/100\n",
      "802/802 [==============================] - 0s - loss: 0.1461 - acc: 0.9514 - val_loss: 3.3966 - val_acc: 0.5224\n",
      "Epoch 58/100\n",
      "802/802 [==============================] - 0s - loss: 0.3260 - acc: 0.9152 - val_loss: 0.3614 - val_acc: 0.8392\n",
      "Epoch 59/100\n",
      "802/802 [==============================] - 0s - loss: 0.1683 - acc: 0.9464 - val_loss: 0.4653 - val_acc: 0.7968\n",
      "Epoch 60/100\n",
      "802/802 [==============================] - 0s - loss: 0.1657 - acc: 0.9352 - val_loss: 0.3672 - val_acc: 0.8379\n",
      "Epoch 61/100\n",
      "802/802 [==============================] - 0s - loss: 0.1398 - acc: 0.9476 - val_loss: 0.4676 - val_acc: 0.7980\n",
      "Epoch 62/100\n",
      "802/802 [==============================] - 0s - loss: 0.1550 - acc: 0.9489 - val_loss: 2.6324 - val_acc: 0.5212\n",
      "Epoch 63/100\n",
      "802/802 [==============================] - 0s - loss: 0.2753 - acc: 0.9190 - val_loss: 0.4145 - val_acc: 0.8254\n",
      "Epoch 64/100\n",
      "802/802 [==============================] - 0s - loss: 0.1495 - acc: 0.9501 - val_loss: 0.3369 - val_acc: 0.8579\n",
      "Epoch 65/100\n",
      "802/802 [==============================] - 0s - loss: 0.1261 - acc: 0.9663 - val_loss: 0.3417 - val_acc: 0.8454\n",
      "Epoch 66/100\n",
      "802/802 [==============================] - 0s - loss: 0.1042 - acc: 0.9751 - val_loss: 0.3403 - val_acc: 0.8479\n",
      "Epoch 67/100\n",
      "802/802 [==============================] - 0s - loss: 0.1131 - acc: 0.9676 - val_loss: 0.4579 - val_acc: 0.8254\n",
      "Epoch 68/100\n",
      "802/802 [==============================] - 0s - loss: 0.1047 - acc: 0.9776 - val_loss: 0.4093 - val_acc: 0.8441\n",
      "Epoch 69/100\n",
      "802/802 [==============================] - 0s - loss: 0.0949 - acc: 0.9763 - val_loss: 0.3601 - val_acc: 0.8504\n",
      "Epoch 70/100\n",
      "802/802 [==============================] - 0s - loss: 0.1103 - acc: 0.9676 - val_loss: 0.4100 - val_acc: 0.8267\n",
      "Epoch 71/100\n",
      "802/802 [==============================] - 0s - loss: 0.1038 - acc: 0.9676 - val_loss: 0.3491 - val_acc: 0.8666\n",
      "Epoch 72/100\n",
      "802/802 [==============================] - 0s - loss: 0.0851 - acc: 0.9788 - val_loss: 1.6918 - val_acc: 0.6421\n",
      "Epoch 73/100\n",
      "802/802 [==============================] - 0s - loss: 0.2302 - acc: 0.9289 - val_loss: 0.5793 - val_acc: 0.7805\n",
      "Epoch 74/100\n",
      "802/802 [==============================] - 0s - loss: 0.1074 - acc: 0.9626 - val_loss: 0.3707 - val_acc: 0.8479\n",
      "Epoch 75/100\n",
      "802/802 [==============================] - 0s - loss: 0.0795 - acc: 0.9838 - val_loss: 0.3809 - val_acc: 0.8429\n",
      "Epoch 76/100\n",
      "802/802 [==============================] - 0s - loss: 0.0671 - acc: 0.9813 - val_loss: 0.3661 - val_acc: 0.8454\n",
      "Epoch 77/100\n",
      "802/802 [==============================] - 0s - loss: 0.0663 - acc: 0.9850 - val_loss: 0.3586 - val_acc: 0.8554\n",
      "Epoch 78/100\n",
      "802/802 [==============================] - 0s - loss: 0.0659 - acc: 0.9825 - val_loss: 0.3965 - val_acc: 0.8404\n",
      "Epoch 79/100\n",
      "802/802 [==============================] - 0s - loss: 0.0748 - acc: 0.9813 - val_loss: 0.9388 - val_acc: 0.7294\n",
      "Epoch 80/100\n",
      "802/802 [==============================] - 0s - loss: 0.1035 - acc: 0.9638 - val_loss: 0.4216 - val_acc: 0.8416\n",
      "Epoch 81/100\n",
      "802/802 [==============================] - 0s - loss: 0.0538 - acc: 0.9938 - val_loss: 0.6425 - val_acc: 0.7993\n",
      "Epoch 82/100\n",
      "802/802 [==============================] - 0s - loss: 0.0582 - acc: 0.9850 - val_loss: 0.4480 - val_acc: 0.8354\n",
      "Epoch 83/100\n",
      "802/802 [==============================] - 0s - loss: 0.0573 - acc: 0.9850 - val_loss: 0.4452 - val_acc: 0.8342\n",
      "Epoch 84/100\n",
      "802/802 [==============================] - 0s - loss: 0.0537 - acc: 0.9888 - val_loss: 0.4066 - val_acc: 0.8529\n",
      "Epoch 85/100\n",
      "802/802 [==============================] - 0s - loss: 0.0393 - acc: 0.9988 - val_loss: 0.4330 - val_acc: 0.8516\n",
      "Epoch 86/100\n",
      "802/802 [==============================] - 0s - loss: 0.0484 - acc: 0.9888 - val_loss: 3.3185 - val_acc: 0.5698\n",
      "Epoch 87/100\n",
      "802/802 [==============================] - 0s - loss: 0.2776 - acc: 0.9364 - val_loss: 5.1264 - val_acc: 0.5150\n",
      "Epoch 88/100\n",
      "802/802 [==============================] - 0s - loss: 0.3580 - acc: 0.9115 - val_loss: 0.4133 - val_acc: 0.8429\n",
      "Epoch 89/100\n",
      "802/802 [==============================] - 0s - loss: 0.0858 - acc: 0.9663 - val_loss: 0.8305 - val_acc: 0.7569\n",
      "Epoch 90/100\n",
      "802/802 [==============================] - 0s - loss: 0.0785 - acc: 0.9726 - val_loss: 0.5818 - val_acc: 0.8017\n",
      "Epoch 91/100\n",
      "802/802 [==============================] - 0s - loss: 0.0667 - acc: 0.9788 - val_loss: 0.3982 - val_acc: 0.8529\n",
      "Epoch 92/100\n",
      "802/802 [==============================] - 0s - loss: 0.0521 - acc: 0.9913 - val_loss: 0.4158 - val_acc: 0.8516\n",
      "Epoch 93/100\n",
      "802/802 [==============================] - 0s - loss: 0.0483 - acc: 0.9888 - val_loss: 0.4740 - val_acc: 0.8367\n",
      "Epoch 94/100\n",
      "802/802 [==============================] - 0s - loss: 0.0492 - acc: 0.9850 - val_loss: 0.4251 - val_acc: 0.8491\n",
      "Epoch 95/100\n",
      "802/802 [==============================] - 0s - loss: 0.0448 - acc: 0.9913 - val_loss: 0.4461 - val_acc: 0.8429\n",
      "Epoch 96/100\n",
      "802/802 [==============================] - 0s - loss: 0.0426 - acc: 0.9913 - val_loss: 2.4389 - val_acc: 0.6671\n",
      "Epoch 97/100\n",
      "802/802 [==============================] - 0s - loss: 0.1231 - acc: 0.9551 - val_loss: 2.2715 - val_acc: 0.5599\n",
      "Epoch 98/100\n",
      "802/802 [==============================] - 0s - loss: 0.1026 - acc: 0.9663 - val_loss: 0.9538 - val_acc: 0.7170\n",
      "Epoch 99/100\n",
      "802/802 [==============================] - 0s - loss: 0.0589 - acc: 0.9850 - val_loss: 0.4636 - val_acc: 0.8466\n",
      "Epoch 100/100\n",
      "802/802 [==============================] - 0s - loss: 0.0411 - acc: 0.9913 - val_loss: 0.4400 - val_acc: 0.8541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb61ddcbdd8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = simple_cnn.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>f084666d</td>\n",
       "      <td>0.070851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7540</th>\n",
       "      <td>16105a8c</td>\n",
       "      <td>0.280635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>719ecd9f</td>\n",
       "      <td>0.003676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  is_iceberg\n",
       "4936  f084666d    0.070851\n",
       "7540  16105a8c    0.280635\n",
       "4504  719ecd9f    0.003676"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = test_df[['id']].copy()\n",
    "pred_df['is_iceberg'] = test_predictions[:,1]\n",
    "pred_df.to_csv('predictions.csv', index = False)\n",
    "pred_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
