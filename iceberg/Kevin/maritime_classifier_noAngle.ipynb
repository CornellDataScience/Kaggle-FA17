{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data\n",
      "reshaping data\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           (None, 75, 75, 2)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 75, 75, 2)         8         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 64)        1216      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 18, 18, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                19275     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 152       \n",
      "=================================================================\n",
      "Total params: 1,890,283\n",
      "Trainable params: 1,887,975\n",
      "Non-trainable params: 2,308\n",
      "_________________________________________________________________\n",
      "Training\n",
      "Train on 3366 samples, validate on 482 samples\n",
      "Epoch 1/250\n",
      "3366/3366 [==============================] - 10s - loss: 0.8796 - acc: 0.5900 - val_loss: 0.6829 - val_acc: 0.5415\n",
      "Epoch 2/250\n",
      "3366/3366 [==============================] - 5s - loss: 0.6289 - acc: 0.6373 - val_loss: 0.6965 - val_acc: 0.3734\n",
      "Epoch 3/250\n",
      "3366/3366 [==============================] - 5s - loss: 0.5761 - acc: 0.6878 - val_loss: 0.6959 - val_acc: 0.4917\n",
      "Epoch 4/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.5158 - acc: 0.7195 - val_loss: 0.6971 - val_acc: 0.5270\n",
      "Epoch 5/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.4740 - acc: 0.7698 - val_loss: 0.7246 - val_acc: 0.5685\n",
      "Epoch 6/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.4416 - acc: 0.7995 - val_loss: 0.6493 - val_acc: 0.6307\n",
      "Epoch 7/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.4063 - acc: 0.8197 - val_loss: 0.7386 - val_acc: 0.5519\n",
      "Epoch 8/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.3924 - acc: 0.8330 - val_loss: 0.6328 - val_acc: 0.6722\n",
      "Epoch 9/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.3716 - acc: 0.8437 - val_loss: 0.8168 - val_acc: 0.6494\n",
      "Epoch 10/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.3513 - acc: 0.8485 - val_loss: 0.6123 - val_acc: 0.7241\n",
      "Epoch 11/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.3436 - acc: 0.8479 - val_loss: 0.5987 - val_acc: 0.7344\n",
      "Epoch 12/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.3346 - acc: 0.8568 - val_loss: 0.7133 - val_acc: 0.7220\n",
      "Epoch 13/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.3416 - acc: 0.8506 - val_loss: 0.6105 - val_acc: 0.7407\n",
      "Epoch 14/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.3131 - acc: 0.8723 - val_loss: 0.6614 - val_acc: 0.7324\n",
      "Epoch 15/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.3274 - acc: 0.8642 - val_loss: 0.3728 - val_acc: 0.8361\n",
      "Epoch 16/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.3095 - acc: 0.8616 - val_loss: 0.4040 - val_acc: 0.8195\n",
      "Epoch 17/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2957 - acc: 0.8761 - val_loss: 0.3144 - val_acc: 0.8589\n",
      "Epoch 18/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2966 - acc: 0.8737 - val_loss: 0.4299 - val_acc: 0.8154\n",
      "Epoch 19/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2837 - acc: 0.8821 - val_loss: 0.3630 - val_acc: 0.8382\n",
      "Epoch 20/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2919 - acc: 0.8818 - val_loss: 0.3699 - val_acc: 0.8278\n",
      "Epoch 21/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2913 - acc: 0.8818 - val_loss: 0.3641 - val_acc: 0.8237\n",
      "Epoch 22/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3366/3366 [==============================] - 6s - loss: 0.2707 - acc: 0.8916 - val_loss: 0.3414 - val_acc: 0.8382\n",
      "Epoch 23/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2586 - acc: 0.8883 - val_loss: 0.4655 - val_acc: 0.8050\n",
      "Epoch 24/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2798 - acc: 0.8862 - val_loss: 0.7015 - val_acc: 0.7552\n",
      "Epoch 25/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2667 - acc: 0.8969 - val_loss: 0.3695 - val_acc: 0.8340\n",
      "Epoch 26/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2687 - acc: 0.8942 - val_loss: 0.4543 - val_acc: 0.8112\n",
      "Epoch 27/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2592 - acc: 0.8951 - val_loss: 0.3792 - val_acc: 0.8237\n",
      "Epoch 28/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2491 - acc: 0.8999 - val_loss: 0.5345 - val_acc: 0.7842\n",
      "Epoch 29/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2446 - acc: 0.8960 - val_loss: 0.3328 - val_acc: 0.8672\n",
      "Epoch 30/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2394 - acc: 0.9037 - val_loss: 0.3845 - val_acc: 0.8465\n",
      "Epoch 31/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2478 - acc: 0.9011 - val_loss: 0.3061 - val_acc: 0.8423\n",
      "Epoch 32/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2147 - acc: 0.9070 - val_loss: 0.4617 - val_acc: 0.8299\n",
      "Epoch 33/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2260 - acc: 0.9076 - val_loss: 0.2314 - val_acc: 0.8921\n",
      "Epoch 34/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2300 - acc: 0.9070 - val_loss: 0.3614 - val_acc: 0.8506\n",
      "Epoch 35/250\n",
      "3366/3366 [==============================] - 5s - loss: 0.2208 - acc: 0.9150 - val_loss: 0.2916 - val_acc: 0.8714\n",
      "Epoch 36/250\n",
      "3366/3366 [==============================] - 4s - loss: 0.2159 - acc: 0.9133 - val_loss: 0.3021 - val_acc: 0.8651\n",
      "Epoch 37/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2072 - acc: 0.9168 - val_loss: 0.3164 - val_acc: 0.8568\n",
      "Epoch 38/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2011 - acc: 0.9225 - val_loss: 0.3245 - val_acc: 0.8610\n",
      "Epoch 39/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2106 - acc: 0.9225 - val_loss: 0.3229 - val_acc: 0.8755\n",
      "Epoch 40/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.2058 - acc: 0.9127 - val_loss: 0.2403 - val_acc: 0.8942\n",
      "Epoch 41/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1960 - acc: 0.9228 - val_loss: 0.2618 - val_acc: 0.8942\n",
      "Epoch 42/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1869 - acc: 0.9234 - val_loss: 0.2481 - val_acc: 0.8859\n",
      "Epoch 43/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1749 - acc: 0.9263 - val_loss: 0.4880 - val_acc: 0.8278\n",
      "Epoch 44/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1801 - acc: 0.9266 - val_loss: 0.3001 - val_acc: 0.8734\n",
      "Epoch 45/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1817 - acc: 0.9251 - val_loss: 0.3263 - val_acc: 0.8714\n",
      "Epoch 46/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1631 - acc: 0.9391 - val_loss: 0.3287 - val_acc: 0.8631\n",
      "Epoch 47/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1730 - acc: 0.9314 - val_loss: 0.4097 - val_acc: 0.8465\n",
      "Epoch 48/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1652 - acc: 0.9323 - val_loss: 0.2532 - val_acc: 0.8942\n",
      "Epoch 49/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1574 - acc: 0.9403 - val_loss: 0.2903 - val_acc: 0.8776\n",
      "Epoch 50/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1599 - acc: 0.9308 - val_loss: 0.3871 - val_acc: 0.8734\n",
      "Epoch 51/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1626 - acc: 0.9352 - val_loss: 0.3094 - val_acc: 0.8900\n",
      "Epoch 52/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1443 - acc: 0.9486 - val_loss: 0.4361 - val_acc: 0.8734\n",
      "Epoch 53/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1489 - acc: 0.9373 - val_loss: 0.3505 - val_acc: 0.8838\n",
      "Epoch 54/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1477 - acc: 0.9439 - val_loss: 0.5243 - val_acc: 0.8423\n",
      "Epoch 55/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1367 - acc: 0.9427 - val_loss: 0.3250 - val_acc: 0.8817\n",
      "Epoch 56/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1529 - acc: 0.9406 - val_loss: 0.3645 - val_acc: 0.8942\n",
      "Epoch 57/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1422 - acc: 0.9439 - val_loss: 0.3920 - val_acc: 0.8859\n",
      "Epoch 58/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1307 - acc: 0.9456 - val_loss: 0.3420 - val_acc: 0.8921\n",
      "Epoch 59/250\n",
      "3366/3366 [==============================] - 6s - loss: 0.1161 - acc: 0.9551 - val_loss: 0.4391 - val_acc: 0.8714\n",
      "predicting\n",
      "creating csv\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os.path as path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.util.montage import montage2d\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv2D, BatchNormalization, Dropout, MaxPooling2D, Dense, Flatten, ZeroPadding2D, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import average, Input, Concatenate\n",
    "from extra_functions import *\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def load_and_format(in_path):\n",
    "    out_df = pd.read_json(in_path)\n",
    "    out_images = out_df.apply(lambda c_row: [np.stack([c_row['band_1'],c_row['band_2']], -1).reshape((75,75,2))],1)\n",
    "    out_images = np.stack(out_images).squeeze()\n",
    "    return out_df, out_images\n",
    "\n",
    "dir_path = path.abspath(path.join('__file__',\"../..\"))\n",
    "train_path = dir_path + \"/train.json\"\n",
    "test_path = dir_path + \"/test.json\"\n",
    "\n",
    "train_df, train_images = load_and_format(train_path)\n",
    "test_df, test_images = load_and_format(test_path)\n",
    "x_angle_test = np.array(test_df.inc_angle)   \n",
    "    \n",
    "\"\"\"\n",
    "x_train, x_val, x_angle_train, x_angle_val, y_train, y_val = train_test_split(train_images\n",
    "                    , x_angle_train, to_categorical(train_df['is_iceberg']), random_state=2017, train_size=0.75)\n",
    "\n",
    "print('Train', x_train.shape, y_train.shape)\n",
    "print('Validation', x_val.shape, y_val.shape) \"\"\"\n",
    "\n",
    "\n",
    "print(\"reading data\")\n",
    "x_train = pd.read_csv('x_train.csv', header=None)\n",
    "x_train = x_train.values\n",
    "y_train = pd.read_csv('y_train.csv', header=None)\n",
    "y_train = y_train.values\n",
    "x_val = pd.read_csv('x_val.csv', header=None)\n",
    "x_val = x_val.values\n",
    "y_val = pd.read_csv('y_val.csv', header=None)\n",
    "y_val = y_val.values  \n",
    "\n",
    "print(\"reshaping data\")\n",
    "x_train = np.reshape(x_train, (3366, 75, 75, 2))\n",
    "x_val = np.reshape(x_val, (482, 75, 75, 2))\n",
    "\n",
    "weight_decay = 0.005\n",
    "\n",
    "image_input = Input(shape=(75, 75, 2), name=\"image\")\n",
    "\n",
    "cnn = BatchNormalization(momentum=0.99)(image_input)\n",
    "\n",
    "#64\n",
    "cnn = Conv2D(64, kernel_size=(3,3), padding = 'same')(cnn)\n",
    "cnn = Activation('relu')(cnn)\n",
    "cnn = BatchNormalization(momentum=0.99)(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2,2))(cnn)\n",
    "cnn = Dropout(0.3)(cnn)\n",
    "\n",
    "#64\n",
    "cnn = Conv2D(64, kernel_size=(3,3), padding = 'same')(cnn)\n",
    "cnn = Activation('relu')(cnn)\n",
    "cnn = BatchNormalization(momentum=0.99)(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2,2))(cnn)\n",
    "cnn = Dropout(0.3)(cnn)\n",
    "\n",
    "#128\n",
    "cnn = Conv2D(128, kernel_size=(3,3), padding = 'same')(cnn)\n",
    "cnn = Activation('relu')(cnn)\n",
    "cnn = BatchNormalization(momentum=0.99)(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2,2))(cnn)\n",
    "cnn = Dropout(0.3)(cnn)\n",
    "\n",
    "#128\n",
    "cnn = Conv2D(128, kernel_size=(3,3), padding = 'same')(cnn)\n",
    "cnn = Activation('relu')(cnn)\n",
    "cnn = BatchNormalization(momentum=0.99)(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2,2))(cnn)\n",
    "cnn = Dropout(0.3)(cnn)\n",
    "\n",
    "#256\n",
    "cnn = Conv2D(256, kernel_size=(3,3), padding = 'same')(cnn)\n",
    "cnn = Activation('relu')(cnn)\n",
    "cnn = BatchNormalization(momentum=0.99)(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2,2))(cnn)\n",
    "cnn = Dropout(0.4)(cnn)\n",
    "\n",
    "#512\n",
    "cnn = Conv2D(512, kernel_size=(3,3), padding = 'same')(cnn)\n",
    "cnn = Activation('relu')(cnn)\n",
    "cnn = BatchNormalization(momentum=0.99)(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2,2))(cnn)\n",
    "cnn = Dropout(0.4)(cnn)\n",
    "\n",
    "cnn = Flatten()(cnn)\n",
    "\n",
    "#256\n",
    "cnn = Dense(256, activation='relu')(cnn)\n",
    "cnn = Dropout(0.4)(cnn)\n",
    "\n",
    "#75\n",
    "cnn = Dense(75, activation='relu')(cnn)\n",
    "cnn = Dropout(0.5)(cnn)\n",
    "\n",
    "output = Dense(2, activation='softmax')(cnn)\n",
    "\n",
    "\n",
    "model = Model(inputs=image_input, outputs=output)\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "print(\"Training\")\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 25)\n",
    "model.fit(x_train, y_train, batch_size = 64, validation_data = (x_val, y_val), \n",
    "          epochs = 250, shuffle = True, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "print(\"predicting\")\n",
    "test_predictions = model.predict(test_images)\n",
    "\n",
    "pred_df = test_df[['id']].copy()\n",
    "pred_df['is_iceberg'] = test_predictions[:,1]\n",
    "print(\"creating csv\")\n",
    "pred_df.to_csv('predictions_4.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
