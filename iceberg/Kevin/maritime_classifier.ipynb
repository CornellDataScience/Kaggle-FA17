{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle shape\n",
      "(1604,)\n",
      "Train (1203, 75, 75, 2) (1203, 2)\n",
      "Validation (401, 75, 75, 2) (401, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "image (InputLayer)               (None, 75, 75, 2)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 75, 75, 2)     8           image[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 75, 75, 16)    304         batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 75, 75, 16)    0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 37, 37, 16)    0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 37, 37, 32)    4640        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 37, 37, 32)    0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 18, 18, 32)    0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 18, 18, 64)    18496       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 18, 18, 64)    0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 9, 9, 64)      0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 9, 9, 64)      36928       max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 9, 9, 64)      0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 4, 4, 64)      0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "angle (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1024)          0           max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 1)             4           angle[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 1025)          0           flatten_1[0][0]                  \n",
      "                                                                   batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 250)           256500      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 250)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 75)            18825       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 75)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2)             152         dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 335,857\n",
      "Trainable params: 335,851\n",
      "Non-trainable params: 6\n",
      "____________________________________________________________________________________________________\n",
      "Training\n",
      "Train on 1203 samples, validate on 401 samples\n",
      "Epoch 1/250\n",
      "1203/1203 [==============================] - 3s - loss: 0.6583 - acc: 0.5919 - val_loss: 0.7647 - val_acc: 0.4938\n",
      "Epoch 2/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.5666 - acc: 0.6933 - val_loss: 0.7369 - val_acc: 0.5661\n",
      "Epoch 3/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.4726 - acc: 0.7747 - val_loss: 0.8064 - val_acc: 0.5686\n",
      "Epoch 4/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.3993 - acc: 0.8171 - val_loss: 0.7241 - val_acc: 0.5935\n",
      "Epoch 5/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.3916 - acc: 0.8221 - val_loss: 0.7222 - val_acc: 0.5910\n",
      "Epoch 6/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.3565 - acc: 0.8387 - val_loss: 0.6137 - val_acc: 0.6584\n",
      "Epoch 7/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.3296 - acc: 0.8587 - val_loss: 0.5425 - val_acc: 0.6958\n",
      "Epoch 8/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.2689 - acc: 0.8861 - val_loss: 0.4727 - val_acc: 0.7431\n",
      "Epoch 9/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.2762 - acc: 0.8861 - val_loss: 0.4265 - val_acc: 0.8155\n",
      "Epoch 10/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.2649 - acc: 0.8936 - val_loss: 0.4136 - val_acc: 0.7980\n",
      "Epoch 11/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.2527 - acc: 0.9002 - val_loss: 0.3504 - val_acc: 0.8529\n",
      "Epoch 12/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.2184 - acc: 0.9135 - val_loss: 0.3166 - val_acc: 0.8579\n",
      "Epoch 13/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.2342 - acc: 0.9061 - val_loss: 0.3540 - val_acc: 0.8504\n",
      "Epoch 14/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.2187 - acc: 0.9144 - val_loss: 0.3032 - val_acc: 0.8703\n",
      "Epoch 15/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.2158 - acc: 0.9160 - val_loss: 0.3362 - val_acc: 0.8354\n",
      "Epoch 16/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.2156 - acc: 0.9094 - val_loss: 0.2920 - val_acc: 0.8703\n",
      "Epoch 17/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1776 - acc: 0.9310 - val_loss: 0.2741 - val_acc: 0.8828\n",
      "Epoch 18/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1654 - acc: 0.9368 - val_loss: 0.2449 - val_acc: 0.9002\n",
      "Epoch 19/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1761 - acc: 0.9335 - val_loss: 0.2826 - val_acc: 0.8753\n",
      "Epoch 20/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1709 - acc: 0.9285 - val_loss: 0.2757 - val_acc: 0.8653\n",
      "Epoch 21/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1685 - acc: 0.9318 - val_loss: 0.2858 - val_acc: 0.8653\n",
      "Epoch 22/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1428 - acc: 0.9451 - val_loss: 0.2295 - val_acc: 0.8953\n",
      "Epoch 23/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1467 - acc: 0.9385 - val_loss: 0.2552 - val_acc: 0.8953\n",
      "Epoch 24/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203/1203 [==============================] - 0s - loss: 0.1477 - acc: 0.9493 - val_loss: 0.2779 - val_acc: 0.8703\n",
      "Epoch 25/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1378 - acc: 0.9476 - val_loss: 0.2284 - val_acc: 0.9077\n",
      "Epoch 26/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1397 - acc: 0.9460 - val_loss: 0.2399 - val_acc: 0.8853\n",
      "Epoch 27/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1514 - acc: 0.9377 - val_loss: 0.2631 - val_acc: 0.8803\n",
      "Epoch 28/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1284 - acc: 0.9543 - val_loss: 0.2757 - val_acc: 0.8678\n",
      "Epoch 29/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1160 - acc: 0.9518 - val_loss: 0.2269 - val_acc: 0.8928\n",
      "Epoch 30/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1411 - acc: 0.9526 - val_loss: 0.2348 - val_acc: 0.8953\n",
      "Epoch 31/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1095 - acc: 0.9576 - val_loss: 0.2663 - val_acc: 0.8678\n",
      "Epoch 32/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0985 - acc: 0.9651 - val_loss: 0.2247 - val_acc: 0.8978\n",
      "Epoch 33/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0924 - acc: 0.9643 - val_loss: 0.2282 - val_acc: 0.8853\n",
      "Epoch 34/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0977 - acc: 0.9559 - val_loss: 0.2599 - val_acc: 0.8728\n",
      "Epoch 35/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0950 - acc: 0.9676 - val_loss: 0.2151 - val_acc: 0.9027\n",
      "Epoch 36/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1082 - acc: 0.9593 - val_loss: 0.2130 - val_acc: 0.9052\n",
      "Epoch 37/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0724 - acc: 0.9717 - val_loss: 0.2266 - val_acc: 0.8978\n",
      "Epoch 38/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0893 - acc: 0.9584 - val_loss: 0.2461 - val_acc: 0.8903\n",
      "Epoch 39/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0670 - acc: 0.9751 - val_loss: 0.2404 - val_acc: 0.8878\n",
      "Epoch 40/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0844 - acc: 0.9609 - val_loss: 0.2109 - val_acc: 0.9052\n",
      "Epoch 41/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0715 - acc: 0.9676 - val_loss: 0.2244 - val_acc: 0.8978\n",
      "Epoch 42/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1148 - acc: 0.9576 - val_loss: 0.2451 - val_acc: 0.8878\n",
      "Epoch 43/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0847 - acc: 0.9684 - val_loss: 0.2535 - val_acc: 0.8803\n",
      "Epoch 44/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.1007 - acc: 0.9651 - val_loss: 0.2518 - val_acc: 0.8803\n",
      "Epoch 45/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0833 - acc: 0.9667 - val_loss: 0.2925 - val_acc: 0.8803\n",
      "Epoch 46/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0704 - acc: 0.9767 - val_loss: 0.2449 - val_acc: 0.8903\n",
      "Epoch 47/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0617 - acc: 0.9751 - val_loss: 0.2695 - val_acc: 0.8828\n",
      "Epoch 48/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0721 - acc: 0.9709 - val_loss: 0.2320 - val_acc: 0.8853\n",
      "Epoch 49/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0766 - acc: 0.9751 - val_loss: 0.2077 - val_acc: 0.9077\n",
      "Epoch 50/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0706 - acc: 0.9726 - val_loss: 0.2367 - val_acc: 0.8903\n",
      "Epoch 51/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0450 - acc: 0.9809 - val_loss: 0.2574 - val_acc: 0.8928\n",
      "Epoch 52/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0446 - acc: 0.9859 - val_loss: 0.2424 - val_acc: 0.8978\n",
      "Epoch 53/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0441 - acc: 0.9850 - val_loss: 0.2282 - val_acc: 0.9002\n",
      "Epoch 54/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0869 - acc: 0.9701 - val_loss: 0.2211 - val_acc: 0.9002\n",
      "Epoch 55/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0671 - acc: 0.9759 - val_loss: 0.2554 - val_acc: 0.8928\n",
      "Epoch 56/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0763 - acc: 0.9676 - val_loss: 0.2145 - val_acc: 0.9002\n",
      "Epoch 57/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0672 - acc: 0.9734 - val_loss: 0.2466 - val_acc: 0.8978\n",
      "Epoch 58/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0630 - acc: 0.9776 - val_loss: 0.2753 - val_acc: 0.8803\n",
      "Epoch 59/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0692 - acc: 0.9792 - val_loss: 0.2331 - val_acc: 0.9102\n",
      "Epoch 60/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0939 - acc: 0.9626 - val_loss: 0.2369 - val_acc: 0.8953\n",
      "Epoch 61/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0709 - acc: 0.9684 - val_loss: 0.3047 - val_acc: 0.8803\n",
      "Epoch 62/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0468 - acc: 0.9875 - val_loss: 0.2412 - val_acc: 0.9002\n",
      "Epoch 63/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0512 - acc: 0.9784 - val_loss: 0.2596 - val_acc: 0.8878\n",
      "Epoch 64/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0396 - acc: 0.9842 - val_loss: 0.2424 - val_acc: 0.9102\n",
      "Epoch 65/250\n",
      "1203/1203 [==============================] - 0s - loss: 0.0376 - acc: 0.9842 - val_loss: 0.2407 - val_acc: 0.9102\n",
      "predicting\n",
      "creating csv\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os.path as path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.util.montage import montage2d\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Conv2D, BatchNormalization, Dropout, MaxPooling2D, Dense, Flatten, ZeroPadding2D, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import average, Input, Concatenate\n",
    "from extra_functions import *\n",
    "\n",
    "\n",
    "def load_and_format(in_path):\n",
    "    out_df = pd.read_json(in_path)\n",
    "    out_images = out_df.apply(lambda c_row: [np.stack([c_row['band_1'],c_row['band_2']], -1).reshape((75,75,2))],1)\n",
    "    out_images = np.stack(out_images).squeeze()\n",
    "    return out_df, out_images\n",
    "\n",
    "dir_path = path.abspath(path.join('__file__',\"../..\"))\n",
    "train_path = dir_path + \"/train.json\"\n",
    "test_path = dir_path + \"/test.json\"\n",
    "\n",
    "train_df, train_images = load_and_format(train_path)\n",
    "test_df, test_images = load_and_format(test_path)\n",
    "train_df.inc_angle = train_df.inc_angle.replace('na', 0)\n",
    "train_df.inc_angle = train_df.inc_angle.astype(float).fillna(0.0)\n",
    "x_angle_train = np.array(train_df.inc_angle)\n",
    "print('angle shape')\n",
    "print(x_angle_train.shape)\n",
    "x_angle_test = np.array(test_df.inc_angle)\n",
    "\n",
    "x_train, x_val, x_angle_train, x_angle_val, y_train, y_val = train_test_split(train_images\n",
    "                    , x_angle_train, to_categorical(train_df['is_iceberg']), random_state=2017, train_size=0.75)\n",
    "\n",
    "print('Train', x_train.shape, y_train.shape)\n",
    "print('Validation', x_val.shape, y_val.shape)\n",
    "\n",
    "\"\"\"\n",
    "print(\"reading data\")\n",
    "x_train = pd.read_csv('x_train.csv', header=None)\n",
    "x_train = x_train.values\n",
    "y_train = pd.read_csv('y_train.csv', header=None)\n",
    "y_train = y_train.values\n",
    "x_val = pd.read_csv('x_val.csv', header=None)\n",
    "x_val = x_val.values\n",
    "y_val = pd.read_csv('y_val.csv', header=None)\n",
    "y_val = y_val.values  \n",
    "\n",
    "print(\"reshaping data\")\n",
    "x_train = np.reshape(x_train, (3366, 75, 75, 2))\n",
    "x_val = np.reshape(x_val, (482, 75, 75, 2)) \"\"\"\n",
    "\n",
    "weight_decay = 0.05\n",
    "\n",
    "image_input = Input(shape=(75, 75, 2), name=\"image\")\n",
    "angle_input = Input(shape=[1], name=\"angle\")\n",
    "\n",
    "cnn = BatchNormalization()(image_input)\n",
    "\n",
    "cnn = Conv2D(16, kernel_size=(3,3), padding = 'same', activation='relu')(cnn)\n",
    "cnn = Dropout(0.2, seed=25)(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2,2))(cnn)\n",
    "\n",
    "cnn = Conv2D(32, kernel_size=(3,3), padding = 'same', activation='relu')(cnn)\n",
    "cnn = Dropout(0.3, seed=25)(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2,2))(cnn)\n",
    "\n",
    "cnn = Conv2D(64, kernel_size=(3,3), padding = 'same', activation='relu')(cnn)\n",
    "cnn = Dropout(0.3, seed=25)(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2,2))(cnn)\n",
    "\n",
    "cnn = Conv2D(64, kernel_size=(3,3), padding = 'same', activation='relu')(cnn)\n",
    "cnn = Dropout(0.3, seed=25)(cnn)\n",
    "cnn = MaxPooling2D(pool_size=(2,2))(cnn)\n",
    "\n",
    "cnn = Flatten()(cnn)\n",
    "concatenated_features = Concatenate()([cnn, BatchNormalization()(angle_input)])\n",
    "\n",
    "cnn = Dense(250, activation='relu')(concatenated_features)\n",
    "cnn = Dropout(0.4, seed=25)(cnn)\n",
    "\n",
    "cnn = Dense(75, activation='relu')(cnn)\n",
    "cnn = Dropout(0.4, seed=25)(cnn)\n",
    "\n",
    "output = Dense(2, activation='softmax')(cnn)\n",
    "\n",
    "\n",
    "model = Model(inputs=[image_input, angle_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "print(\"Training\")\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 15)\n",
    "model.fit([x_train, x_angle_train], y_train, batch_size = 64, validation_data = ([x_val, x_angle_val], y_val), \n",
    "          epochs = 250, shuffle = True, callbacks=[early_stopping])\n",
    "\n",
    "print(\"predicting\")\n",
    "test_predictions = model.predict([test_images, x_angle_test])\n",
    "\n",
    "pred_df = test_df[['id']].copy()\n",
    "pred_df['is_iceberg'] = test_predictions[:,1]\n",
    "print(\"creating csv\")\n",
    "pred_df.to_csv('predictions_2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
