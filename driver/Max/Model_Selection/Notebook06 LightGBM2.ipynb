{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook 06 Lightgbm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timeline: 2017/11/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Fork from https://www.kaggle.com/the1owl/forza-baseline-lightgbm-example and compare the results with own lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "45ba73d4-6c4c-40bb-9390-7dfc956c555d",
    "_uuid": "dbd332f83c89108c4e641218f5c4e7b9cd325b80",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters used in the kernel\n",
    "MAX_ROUNDS = 1200\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Import Packages, define functions and import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b7258128-55f9-4543-8611-5e0a6661837b",
    "_uuid": "72171ee53e170096d37a18eef84682fa348ae5c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from numba import jit\n",
    "from sklearn import *\n",
    "import lightgbm as lgb\n",
    "from multiprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "3d16f16e-12cc-4b41-b7bd-fa05ce44770c",
    "_uuid": "154b078a7e86c0a5a328118a61d28e2581bb3b0a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "def gini_lgb(preds, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = eval_gini(y, preds) / eval_gini(y, y)\n",
    "    return 'gini', score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "52b50086-b405-4598-b11c-97887cdcce8e",
    "_uuid": "07a5a5782894611e9006ae1b399b0b8fb8a0f06b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_df = pd.read_csv('/Users/maxji/Desktop/Kaggle/0SafeDriver/data/train.csv') # .iloc[0:200,:]\n",
    "test_df = pd.read_csv('/Users/maxji/Desktop/Kaggle/0SafeDriver/data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "7f8f84f9-aa46-43d6-8d78-619ef9a7dcce",
    "_uuid": "affb627af275ad7aa0c5c85dd826ee140370eb3e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions for manipulating data\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c: #standard arithmetic\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "    for c in one_hot:\n",
    "        if len(one_hot[c])>2 and len(one_hot[c]) < 7:\n",
    "            for val in one_hot[c]:\n",
    "                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)\n",
    "    return df\n",
    "\n",
    "def multi_transform(df):\n",
    "    p = Pool(cpu_count())\n",
    "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "    p.close(); p.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "1b36eb15-ee01-43a3-8766-27650f98158d",
    "_uuid": "6255e3c12616b0279cef5c1bdec97751bb72d8b8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process data\n",
    "col = [c for c in train_df.columns if c not in ['id','target']]\n",
    "col = [c for c in col if not c.startswith('ps_calc_')]\n",
    "\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "\n",
    "y = train_df['target']\n",
    "X = train_df[col]\n",
    "y_valid_pred = 0*y\n",
    "X_test = test_df.drop(['id'], axis=1)\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "7c6e4823-4e8c-4408-b961-576d469e9241",
    "_uuid": "6aa7ada2193c2e4b8a63eebda925cee5023b45b0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up folds\n",
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d8108f3-e9e8-45d6-93b5-740eb7b4b10b",
    "_uuid": "581c3f15f294378a0e2ac3305e9e3d375f664b21",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up classifier\n",
    "params = {\n",
    "    'learning_rate': LEARNING_RATE, \n",
    "    'max_depth': 4, \n",
    "    'lambda_l1': 16.7,\n",
    "    'boosting': 'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc',\n",
    "    'feature_fraction': .7,\n",
    "    'is_training_metric': False, \n",
    "    'seed': 99\n",
    "}\n",
    "\n",
    "\"\"\"lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.02\n",
    "lgb_params['n_estimators'] = 650\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['seed'] = 99\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c4e48347-920f-4ba7-8b37-cfbaab4c3c00",
    "_uuid": "2b9ed96c98b705d3e4bf2a3d60323dfab4332674",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n"
     ]
    }
   ],
   "source": [
    "# Run Training and CV\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    \n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index].copy()\n",
    "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "    test = test_df.copy()[col]\n",
    "    print( \"\\nFold \", i)\n",
    "\n",
    "    # Transform data for this fold\n",
    "    one_hot = {c: list(X_train[c].unique()) for c in X_train.columns}\n",
    "    X_train = X_train.replace(-1, np.NaN)  # Get rid of -1 while computing summary stats\n",
    "    d_median = X_train.median(axis=0)\n",
    "    d_mean = X_train.mean(axis=0)\n",
    "    X_train = X_train.fillna(-1)  # Restore -1 for missing values\n",
    "\n",
    "    X_train = multi_transform(X_train)\n",
    "    X_valid = multi_transform(X_valid)\n",
    "    test = multi_transform(test)\n",
    "\n",
    "    # Run model for this fold\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        fit_model = lgb.train( \n",
    "                               params, \n",
    "                               lgb.Dataset(X_train, label=y_train), \n",
    "                               MAX_ROUNDS, \n",
    "                               lgb.Dataset(X_valid, label=y_valid), \n",
    "                               verbose_eval=50, \n",
    "                               feval=gini_lgb, \n",
    "                               early_stopping_rounds=200 \n",
    "                             )\n",
    "        print( \" Best iteration = \", fit_model.best_iteration )\n",
    "        pred = fit_model.predict(X_valid, num_iteration=fit_model.best_iteration)\n",
    "        test_pred = fit_model.predict(test[col], num_iteration=fit_model.best_iteration)\n",
    "    else:\n",
    "        fit_model = lgb.train( \n",
    "                               params, \n",
    "                               lgb.Dataset(X_train, label=y_train), \n",
    "                               #MAX_ROUNDS, \n",
    "                               verbose_eval=50 \n",
    "                             )\n",
    "        pred = fit_model.predict(X_valid)\n",
    "        test_pred = fit_model.predict(test)\n",
    "\n",
    "    # Save validation predictions for this fold\n",
    "    print( \"  Gini = \", eval_gini(y_valid, pred) )\n",
    "    y_valid_pred.iloc[test_index] = (np.exp(pred) - 1.0).clip(0,1)\n",
    "    \n",
    "    # Accumulate test set predictions\n",
    "    y_test_pred += (np.exp(test_pred) - 1.0).clip(0,1)\n",
    "    \n",
    "y_test_pred /= K  # Average test set predictions\n",
    "\n",
    "print( \"\\nGini for full training set:\" )\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e3dfd76-c566-4b8d-a460-b56e964d0772",
    "_uuid": "e61bf4e22c1c29c8358caeecb6e67d6658f2005d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save validation predictions for stacking/ensembling\n",
    "val = pd.DataFrame()\n",
    "val['id'] = id_train\n",
    "val['target'] = y_valid_pred.values\n",
    "val.to_csv('lgb_valid.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f4cbef2c-e52b-4afb-b8ef-904ee9b5f9d5",
    "_uuid": "380fc8053d00cd8bb2796bfd2b59d10cbc4ce7e1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv('lgb_submit.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca9594fa-57ce-4393-9b1c-3383310e83a3",
    "_uuid": "539c2db7c30cecbb9f37dc006b1b81fedd349b87",
    "collapsed": true
   },
   "source": [
    "Insight:\n",
    "This is forked from an online kernel which does better (0.282) than my own (0.281). Its transform methods needs further research. It might be possible to stack the two models together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
