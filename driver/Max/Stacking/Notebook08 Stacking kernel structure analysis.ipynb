{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook08 Stacking Kernel structure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timeline: 2017/11/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Look at Kernels online and develop a structure for stacking a large number of kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Import Packages, define functions and import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:261: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:379: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1660: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1844: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:2017: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:2161: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\omp.py:349: DeprecationWarning: invalid escape sequence \\g\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "# Starting time: 12:07\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Training packages\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Ensemble\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions that might be useful\n",
    "\n",
    "# 01 Gini coefficient calculations\n",
    "# https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "# 02 Gini coefficient for xgb and lgb\n",
    "# https://www.kaggle.com/rshally/porto-xgb-lgb-kfold-lb-0-282  (Version 1)\n",
    "def gini_xgb(pred, y):\n",
    "    y = y.get_label()\n",
    "    return 'gini', gini(y, pred) / gini(y, y)\n",
    "\n",
    "def gini_lgb(preds, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = gini(y, preds) / gini(y, y)\n",
    "    return 'gini', score, True\n",
    "\n",
    "# 03 The Ensemble function\n",
    "# https://www.kaggle.com/yekenot/simple-stacker-lb-0-284/code (Version 8)\n",
    "class Ensemble(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "#                y_holdout = y[test_idx]\n",
    "\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "#                cross_score = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "#                print(\"    cross_score: %.5f\" % (cross_score.mean()))\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "        results = cross_val_score(self.stacker, S_train, y, cv=3, scoring='roc_auc')\n",
    "        print(\"Stacker score: %.5f\" % (results.mean()))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict_proba(S_test)[:,1]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n",
      "(595212, 59) (892816, 58)\n"
     ]
    }
   ],
   "source": [
    "# Loading Files and Picking out NA values\n",
    "# It seems that if we don't pick out NA values, there will be one missing value in the id column\n",
    "print('loading files...')\n",
    "train = pd.read_csv('/Users/maxji/Desktop/Kaggle/0SafeDriver/data/train.csv', na_values=-1)\n",
    "test = pd.read_csv('/Users/maxji/Desktop/Kaggle/0SafeDriver/data/test.csv', na_values=-1)\n",
    "\n",
    "# Change format to reduce memory usage\n",
    "for c in train.select_dtypes(include=['float64']).columns:\n",
    "    train[c]=train[c].astype(np.float32)\n",
    "    test[c]=test[c].astype(np.float32)\n",
    "for c in train.select_dtypes(include=['int64']).columns[2:]:\n",
    "    train[c]=train[c].astype(np.int8)\n",
    "    test[c]=test[c].astype(np.int8)  \n",
    "\n",
    "# Print out the shape of train and test\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 200) (892816, 199)\n"
     ]
    }
   ],
   "source": [
    "# 01 Dropping Columns starting with Calc\n",
    "# Note: This is used by almost all kernels online. \n",
    "# Justification: https://www.kaggle.com/arthurtok/interactive-porto-insights-a-plot-ly-tutorial\n",
    "# At least in Gradient Boosting, the calc variables all show really low correlation with target.\n",
    "\n",
    "col_to_drop = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "train = train.drop(col_to_drop, axis=1)  \n",
    "test = test.drop(col_to_drop, axis=1) \n",
    "\n",
    "# 02 Treating missing values:\n",
    "# Again, different ways are employed by different Kernels.\n",
    "# a. Kernels that doesn't treat values (Keep NA in the data)\n",
    "# https://www.kaggle.com/rshally/porto-xgb-lgb-kfold-lb-0-282  (Version 1)\n",
    "# b. Kernels that keep NA values as -1\n",
    "# c. Kernels that change NA values to 999/-999\n",
    "\n",
    "# 03 Dealing with categorical variables\n",
    "# a. Make up dummy variables for each of them\n",
    "# Note: This will increase the number of variables, so need more parameter tuning\n",
    "\"\"\"cat_features = [a for a in train.columns if a.endswith('cat')]\n",
    "for column in cat_features:\n",
    "    temp = pd.get_dummies(pd.Series(train[column]))\n",
    "    train = pd.concat([train,temp],axis=1)\n",
    "    train = train.drop([column],axis=1)\n",
    "    \n",
    "for column in cat_features:\n",
    "    temp = pd.get_dummies(pd.Series(test[column]))\n",
    "    test = pd.concat([test,temp],axis=1)\n",
    "    test = test.drop([column],axis=1)\n",
    "\n",
    "print(train.shape,test.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.952120e+05</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.438036e+05</td>\n",
       "      <td>0.036448</td>\n",
       "      <td>1.900378</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.257033</td>\n",
       "      <td>0.163921</td>\n",
       "      <td>0.185304</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.020231</td>\n",
       "      <td>0.007468</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.040762</td>\n",
       "      <td>0.142946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.293678e+05</td>\n",
       "      <td>0.187401</td>\n",
       "      <td>1.983789</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>0.388544</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077084</td>\n",
       "      <td>0.058912</td>\n",
       "      <td>0.049870</td>\n",
       "      <td>0.069031</td>\n",
       "      <td>0.140791</td>\n",
       "      <td>0.086094</td>\n",
       "      <td>0.110354</td>\n",
       "      <td>0.059336</td>\n",
       "      <td>0.197738</td>\n",
       "      <td>0.350018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.719915e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.435475e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.115549e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.488027e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         target      ps_ind_01      ps_ind_03  \\\n",
       "count  5.952120e+05  595212.000000  595212.000000  595212.000000   \n",
       "mean   7.438036e+05       0.036448       1.900378       4.423318   \n",
       "std    4.293678e+05       0.187401       1.983789       2.699902   \n",
       "min    7.000000e+00       0.000000       0.000000       0.000000   \n",
       "25%    3.719915e+05       0.000000       0.000000       2.000000   \n",
       "50%    7.435475e+05       0.000000       1.000000       4.000000   \n",
       "75%    1.115549e+06       0.000000       3.000000       6.000000   \n",
       "max    1.488027e+06       1.000000       7.000000      11.000000   \n",
       "\n",
       "       ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.393742       0.257033       0.163921       0.185304   \n",
       "std         0.488579       0.436998       0.370205       0.388544   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       1.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_10_bin  ps_ind_11_bin      ...                   95  \\\n",
       "count  595212.000000  595212.000000      ...        595212.000000   \n",
       "mean        0.000373       0.001692      ...             0.005978   \n",
       "std         0.019309       0.041097      ...             0.077084   \n",
       "min         0.000000       0.000000      ...             0.000000   \n",
       "25%         0.000000       0.000000      ...             0.000000   \n",
       "50%         0.000000       0.000000      ...             0.000000   \n",
       "75%         0.000000       0.000000      ...             0.000000   \n",
       "max         1.000000       1.000000      ...             1.000000   \n",
       "\n",
       "                  96             97             98             99  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.003483       0.002493       0.004788       0.020231   \n",
       "std         0.058912       0.049870       0.069031       0.140791   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                 100            101            102            103  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.007468       0.012330       0.003533       0.040762   \n",
       "std         0.086094       0.110354       0.059336       0.197738   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                 104  \n",
       "count  595212.000000  \n",
       "mean        0.142946  \n",
       "std         0.350018  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Preparation for Training\n",
    "# 01 Dropping columns, separating target function (y) and features (X)\n",
    "#  X: The values of feature dataframe\n",
    "#  y: target dataframe\n",
    "#  features: The columns of feature dataframe\n",
    "X = train.drop(['id', 'target'], axis=1)\n",
    "features = X.columns\n",
    "X = X.values\n",
    "y = train['target'].values\n",
    "\n",
    "# 02 Create and prepare the submission dataset\n",
    "#  sub: The submission dataframe \n",
    "sub=test['id'].to_frame()\n",
    "sub['target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training parameters \n",
    "# 01 xgboost\n",
    "# https://www.kaggle.com/rshally/porto-xgb-lgb-kfold-lb-0-282   (Version 1)\n",
    "\"\"\"params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, \n",
    "          'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent': True}\"\"\"\n",
    "# local cv: 0.2848016, lb: 0.281\n",
    "\n",
    "\n",
    "# 02 lightgbm\n",
    "# https://www.kaggle.com/rshally/porto-xgb-lgb-kfold-lb-0-282   (Version 1)\n",
    "\n",
    "# @鲲(China) lgbm is very sensitive with hyper parameters, my lgbm give me 0.281. Here's my suggestion, \n",
    "# use a small max_depth and a num_of_leaves smaller than 2**max_depth, also try bagging with a small bagging frequency\n",
    "params = {'metric': 'auc', 'learning_rate' : 0.01, 'max_depth':10, 'max_bin':10,  'objective': 'binary', \n",
    "          'feature_fraction': 0.8,'bagging_fraction':0.9,'bagging_freq':10,  'min_data': 500}\n",
    "# local cv: 0.284789, lb: 0.281\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "# There has been some arguments on both sides for KFold and Stratified KFold. Need to investigate more.\n",
    "# Discussion:\n",
    "# @KALE I am now using Stratified 5Fold for my cv. But lgb cv score doesn't seem consistent with lb score. \n",
    "# lgb 0.282 - lb 0.279; lgb 0.281 - lb 0.280\n",
    "# @鲲(China) 3 fold without Stratified is very consistent with lb in my side\n",
    "\n",
    "# Personally, I feel that Stratified Kfold should be better, because the dataset has a imbalanced target, \n",
    "# and Stratified Kfold will try to balance out the different classes (0,1) in the target.\n",
    "\n",
    "# https://www.kaggle.com/rshally/porto-xgb-lgb-kfold-lb-0-282   (Version 1)\n",
    "nrounds=2000 \n",
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i, (train_index, test_index) in enumerate(skf.split(X, y)):\\n    print(' xgb kfold: {}  of  {} : '.format(i+1, kfold))\\n    X_train, X_valid = X[train_index], X[test_index]\\n    y_train, y_valid = y[train_index], y[test_index]\\n    \\n    d_train = xgb.DMatrix(X_train, y_train) \\n    d_valid = xgb.DMatrix(X_valid, y_valid) \\n    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\\n    xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100, \\n                          feval=gini_xgb, maximize=True, verbose_eval=100)\\n    prediction = xgb_model.predict(xgb.DMatrix(test[features].values), \\n                        ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\\n    sub['target'] += prediction\\n    \\ngc.collect()\\nsub.head(2)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual Training\n",
    "# 01 xgboost\n",
    "# https://www.kaggle.com/rshally/porto-xgb-lgb-kfold-lb-0-282   (Version 1)\n",
    "# Running time: ~45min\n",
    "\n",
    "# About xgb_model.best_ntree_limit+50: \n",
    "# @Rudolph The credit for that goes to The1owl - it is not imperative but it seems to improve things a bit.\n",
    "# @David Yang xgb_model.best_ntree_limit+50 seems to be unnecessary but it may get a good result.I think this way is useful to lgb, too. \n",
    "# You can change the +n/-n just like a parameter if it would imporove your result.\n",
    "\"\"\"for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(' xgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    \n",
    "    d_train = xgb.DMatrix(X_train, y_train) \n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid) \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100, \n",
    "                          feval=gini_xgb, maximize=True, verbose_eval=100)\n",
    "    prediction = xgb_model.predict(xgb.DMatrix(test[features].values), \n",
    "                        ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n",
    "    sub['target'] += prediction\n",
    "    \n",
    "gc.collect()\n",
    "sub.head(2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lgb kfold: 1  of  2 : \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\tvalid_0's auc: 0.620841\tvalid_0's gini: 0.241691\n",
      "[20]\tvalid_0's auc: 0.623424\tvalid_0's gini: 0.24685\n",
      "[30]\tvalid_0's auc: 0.62626\tvalid_0's gini: 0.252521\n",
      "[40]\tvalid_0's auc: 0.628462\tvalid_0's gini: 0.256924\n",
      "[50]\tvalid_0's auc: 0.630364\tvalid_0's gini: 0.260728\n",
      "[60]\tvalid_0's auc: 0.631282\tvalid_0's gini: 0.262564\n",
      "[70]\tvalid_0's auc: 0.63218\tvalid_0's gini: 0.264361\n",
      "[80]\tvalid_0's auc: 0.632385\tvalid_0's gini: 0.264771\n",
      "[90]\tvalid_0's auc: 0.632935\tvalid_0's gini: 0.26587\n",
      "[100]\tvalid_0's auc: 0.634087\tvalid_0's gini: 0.268174\n",
      "[110]\tvalid_0's auc: 0.634799\tvalid_0's gini: 0.269598\n",
      "[120]\tvalid_0's auc: 0.635491\tvalid_0's gini: 0.270983\n",
      "[130]\tvalid_0's auc: 0.636165\tvalid_0's gini: 0.272331\n",
      "[140]\tvalid_0's auc: 0.636787\tvalid_0's gini: 0.273575\n",
      "[150]\tvalid_0's auc: 0.637315\tvalid_0's gini: 0.27463\n",
      "[160]\tvalid_0's auc: 0.637797\tvalid_0's gini: 0.275595\n",
      "[170]\tvalid_0's auc: 0.638091\tvalid_0's gini: 0.276182\n",
      "[180]\tvalid_0's auc: 0.638434\tvalid_0's gini: 0.276868\n",
      "[190]\tvalid_0's auc: 0.638654\tvalid_0's gini: 0.277307\n",
      "[200]\tvalid_0's auc: 0.638631\tvalid_0's gini: 0.277262\n",
      "[210]\tvalid_0's auc: 0.638944\tvalid_0's gini: 0.277887\n",
      "[220]\tvalid_0's auc: 0.639117\tvalid_0's gini: 0.278234\n",
      "[230]\tvalid_0's auc: 0.639153\tvalid_0's gini: 0.278307\n",
      "[240]\tvalid_0's auc: 0.639506\tvalid_0's gini: 0.279013\n",
      "[250]\tvalid_0's auc: 0.639773\tvalid_0's gini: 0.279546\n",
      "[260]\tvalid_0's auc: 0.639829\tvalid_0's gini: 0.279658\n",
      "[270]\tvalid_0's auc: 0.639772\tvalid_0's gini: 0.279544\n",
      "[280]\tvalid_0's auc: 0.639786\tvalid_0's gini: 0.279572\n",
      "[290]\tvalid_0's auc: 0.639631\tvalid_0's gini: 0.279261\n",
      "[300]\tvalid_0's auc: 0.639802\tvalid_0's gini: 0.279605\n",
      "[310]\tvalid_0's auc: 0.63971\tvalid_0's gini: 0.27942\n",
      "[320]\tvalid_0's auc: 0.639808\tvalid_0's gini: 0.279617\n",
      "[330]\tvalid_0's auc: 0.639803\tvalid_0's gini: 0.279606\n",
      "[340]\tvalid_0's auc: 0.639847\tvalid_0's gini: 0.279694\n",
      "[350]\tvalid_0's auc: 0.639972\tvalid_0's gini: 0.279944\n",
      "[360]\tvalid_0's auc: 0.640256\tvalid_0's gini: 0.280513\n",
      "[370]\tvalid_0's auc: 0.640349\tvalid_0's gini: 0.280697\n",
      "[380]\tvalid_0's auc: 0.640398\tvalid_0's gini: 0.280796\n",
      "[390]\tvalid_0's auc: 0.640373\tvalid_0's gini: 0.280746\n",
      "[400]\tvalid_0's auc: 0.640198\tvalid_0's gini: 0.280396\n",
      "[410]\tvalid_0's auc: 0.640188\tvalid_0's gini: 0.280376\n",
      "[420]\tvalid_0's auc: 0.640146\tvalid_0's gini: 0.280292\n",
      "[430]\tvalid_0's auc: 0.640053\tvalid_0's gini: 0.280106\n",
      "[440]\tvalid_0's auc: 0.640079\tvalid_0's gini: 0.280158\n",
      "[450]\tvalid_0's auc: 0.640004\tvalid_0's gini: 0.280009\n",
      "[460]\tvalid_0's auc: 0.640004\tvalid_0's gini: 0.280009\n",
      "[470]\tvalid_0's auc: 0.639864\tvalid_0's gini: 0.279727\n",
      "Early stopping, best iteration is:\n",
      "[378]\tvalid_0's auc: 0.640412\tvalid_0's gini: 0.280823\n",
      " lgb kfold: 2  of  2 : \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\tvalid_0's auc: 0.617139\tvalid_0's gini: 0.234261\n",
      "[20]\tvalid_0's auc: 0.620594\tvalid_0's gini: 0.241191\n",
      "[30]\tvalid_0's auc: 0.623199\tvalid_0's gini: 0.246401\n",
      "[40]\tvalid_0's auc: 0.625108\tvalid_0's gini: 0.250218\n",
      "[50]\tvalid_0's auc: 0.626739\tvalid_0's gini: 0.253479\n",
      "[60]\tvalid_0's auc: 0.628633\tvalid_0's gini: 0.257266\n",
      "[70]\tvalid_0's auc: 0.629599\tvalid_0's gini: 0.259198\n",
      "[80]\tvalid_0's auc: 0.63049\tvalid_0's gini: 0.26098\n",
      "[90]\tvalid_0's auc: 0.631486\tvalid_0's gini: 0.262972\n",
      "[100]\tvalid_0's auc: 0.632033\tvalid_0's gini: 0.264066\n",
      "[110]\tvalid_0's auc: 0.632799\tvalid_0's gini: 0.265598\n",
      "[120]\tvalid_0's auc: 0.633372\tvalid_0's gini: 0.266744\n",
      "[130]\tvalid_0's auc: 0.634289\tvalid_0's gini: 0.268577\n",
      "[140]\tvalid_0's auc: 0.634638\tvalid_0's gini: 0.269276\n",
      "[150]\tvalid_0's auc: 0.635079\tvalid_0's gini: 0.270159\n",
      "[160]\tvalid_0's auc: 0.635659\tvalid_0's gini: 0.271318\n",
      "[170]\tvalid_0's auc: 0.636015\tvalid_0's gini: 0.272029\n",
      "[180]\tvalid_0's auc: 0.636478\tvalid_0's gini: 0.272956\n",
      "[190]\tvalid_0's auc: 0.636564\tvalid_0's gini: 0.273129\n",
      "[200]\tvalid_0's auc: 0.636998\tvalid_0's gini: 0.273995\n",
      "[210]\tvalid_0's auc: 0.636968\tvalid_0's gini: 0.273936\n",
      "[220]\tvalid_0's auc: 0.637152\tvalid_0's gini: 0.274305\n",
      "[230]\tvalid_0's auc: 0.637251\tvalid_0's gini: 0.274503\n",
      "[240]\tvalid_0's auc: 0.637218\tvalid_0's gini: 0.274437\n",
      "[250]\tvalid_0's auc: 0.637223\tvalid_0's gini: 0.274445\n",
      "[260]\tvalid_0's auc: 0.637377\tvalid_0's gini: 0.274753\n",
      "[270]\tvalid_0's auc: 0.637388\tvalid_0's gini: 0.274776\n",
      "[280]\tvalid_0's auc: 0.637612\tvalid_0's gini: 0.275224\n",
      "[290]\tvalid_0's auc: 0.637539\tvalid_0's gini: 0.275078\n",
      "[300]\tvalid_0's auc: 0.637467\tvalid_0's gini: 0.274935\n",
      "[310]\tvalid_0's auc: 0.637418\tvalid_0's gini: 0.274836\n",
      "[320]\tvalid_0's auc: 0.637434\tvalid_0's gini: 0.274867\n",
      "[330]\tvalid_0's auc: 0.637489\tvalid_0's gini: 0.274978\n",
      "[340]\tvalid_0's auc: 0.637413\tvalid_0's gini: 0.274827\n",
      "[350]\tvalid_0's auc: 0.637304\tvalid_0's gini: 0.274609\n",
      "[360]\tvalid_0's auc: 0.637396\tvalid_0's gini: 0.274792\n",
      "[370]\tvalid_0's auc: 0.637394\tvalid_0's gini: 0.274787\n",
      "[380]\tvalid_0's auc: 0.637308\tvalid_0's gini: 0.274616\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's auc: 0.637612\tvalid_0's gini: 0.275224\n"
     ]
    }
   ],
   "source": [
    "# 02 LightGBM\n",
    "# https://www.kaggle.com/rshally/porto-xgb-lgb-kfold-lb-0-282   (Version 1)\n",
    "# Running Time:\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=1)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(' lgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
    "    X_train, X_eval = X[train_index], X[test_index]\n",
    "    y_train, y_eval = y[train_index], y[test_index]\n",
    "    lgb_model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), nrounds, \n",
    "                  lgb.Dataset(X_eval, label=y_eval), verbose_eval=10, \n",
    "                  feval=gini_lgb, early_stopping_rounds=100)\n",
    "    sub['target'] += lgb_model.predict(test[features].values, \n",
    "                        num_iteration=lgb_model.best_iteration) / (kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.057703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.062681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    target\n",
       "0   0  0.057703\n",
       "1   1  0.062681"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.to_csv('submission_5.csv', index=False, float_format='%.5f') \n",
    "gc.collect()\n",
    "sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.928160e+05</td>\n",
       "      <td>892816.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.441535e+05</td>\n",
       "      <td>0.059406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.296830e+05</td>\n",
       "      <td>0.019694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.009830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.720218e+05</td>\n",
       "      <td>0.045099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.443070e+05</td>\n",
       "      <td>0.056896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.116308e+06</td>\n",
       "      <td>0.070877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.488026e+06</td>\n",
       "      <td>0.183574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         target\n",
       "count  8.928160e+05  892816.000000\n",
       "mean   7.441535e+05       0.059406\n",
       "std    4.296830e+05       0.019694\n",
       "min    0.000000e+00       0.009830\n",
       "25%    3.720218e+05       0.045099\n",
       "50%    7.443070e+05       0.056896\n",
       "75%    1.116308e+06       0.070877\n",
       "max    1.488026e+06       0.183574"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Insight:<br>\n",
    "This kernel is mainly combining several kernels online and justifying every step inside, to help understand stacking better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
