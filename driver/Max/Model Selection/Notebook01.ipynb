{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook01 for Safe Driver Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals: Give Numerical Illustrations of Data <br>\n",
    "Version 2: Added RandomForestClassifier (Which shows Classifiers would not work for this problem.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Import Packages and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# display\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Files\n",
    "train_df = pd.read_csv('/Users/maxji/Desktop/Kaggle/0SafeDriver/data/train.csv')\n",
    "test_df = pd.read_csv('/Users/maxji/Desktop/Kaggle/0SafeDriver/data/test.csv')\n",
    "submission_df = pd.read_csv('/Users/maxji/Desktop/Kaggle/0SafeDriver/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of data: <br>\n",
    "(1) A total of 595212 train data and 892816 test data <br>\n",
    "(2) Data Types: id and target(binary), 14 Categorical Variables (cat), 17 Binary Variables (bin),  10 Continuous Variables(reg_01-03,car_12-15,calc_01-03), 16 Ordinal Variables <br>\n",
    "(3) Data Categories: ind 18, reg 3, car 16, calc 20 <br>\n",
    "(4) Missing data: ind_02,04,05_cat, car_01,02,03,05,07,09_cat, car_11,12,14, reg_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pick out columns with specific keyword inside\n",
    "def select_cols(df,description):\n",
    "    get_cols = [col for col in df.columns if description in col]\n",
    "    return df[get_cols]\n",
    "\n",
    "# Remove -1 in the code and replace with N/A\n",
    "def recover_na(df):\n",
    "    df = df.replace(-1, np.NaN)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select columns with specific data type (w/o price)\n",
    "cat_cols = select_cols(train_df,'cat')\n",
    "bin_cols = select_cols(train_df,'bin')\n",
    "cont_cols = train_df.select_dtypes(include=['float64'])\n",
    "temp_cols = [col for col in train_df.columns if ('cat' not in col) and ('bin' not in col) and (train_df[col].dtype != float) \n",
    "            and ('id' not in col) and ('target' not in col)]\n",
    "ord_cols = train_df[temp_cols]\n",
    "\n",
    "# Select columns with specific category\n",
    "ind_cols = select_cols(train_df,'ind')\n",
    "reg_cols = select_cols(train_df,'reg')\n",
    "car_cols = select_cols(train_df,'car')\n",
    "calc_cols = select_cols(train_df,'calc')\n",
    "\n",
    "# Recover NAs from the file\n",
    "train_recna = recover_na(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since the target function is pretty biased (97% with 0 and 3% with 1), we try to make copies of the entries\n",
    "# with target value 1 to minimize the bias caused by distribution.\n",
    "target_achieved = train_df['target']==1\n",
    "df_copy = train_df[target_achieved]\n",
    "train_df = train_df.append([df_copy]*5,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = train_df.drop(['target', 'id'], axis=1)\n",
    "y_all = train_df['target']\n",
    "\n",
    "num_test = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=100, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=200, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import training model and CV package\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Choose the type of classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "# In this first notebook I'm playing with GridSearch. The following parameters are not optimal.\n",
    "\"\"\"parameters = {'n_estimators': [4, 6, 9], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]\n",
    "             }\"\"\"\n",
    "parameters = {'n_estimators': [200], \n",
    "              'max_features': ['log2','sqrt','auto'], \n",
    "              'criterion': ['gini','entropy'],\n",
    "              'max_depth': [5], \n",
    "              'min_samples_split': [100],\n",
    "              #'min_samples_leaf': [4]\n",
    "             }\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816146429155\n"
     ]
    }
   ],
   "source": [
    "# Create Predictions\n",
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 0.9444444444444444\n",
      "Fold 2 accuracy: 0.8888888888888888\n",
      "Fold 3 accuracy: 0.8888888888888888\n",
      "Fold 4 accuracy: 0.9444444444444444\n",
      "Fold 5 accuracy: 0.9444444444444444\n",
      "Fold 6 accuracy: 1.0\n",
      "Fold 7 accuracy: 0.9444444444444444\n",
      "Fold 8 accuracy: 1.0\n",
      "Fold 9 accuracy: 1.0\n",
      "Fold 10 accuracy: 1.0\n",
      "Fold 11 accuracy: 0.9444444444444444\n",
      "Fold 12 accuracy: 1.0\n",
      "Fold 13 accuracy: 0.9444444444444444\n",
      "Fold 14 accuracy: 0.8888888888888888\n",
      "Fold 15 accuracy: 0.8888888888888888\n",
      "Fold 16 accuracy: 1.0\n",
      "Fold 17 accuracy: 0.8333333333333334\n",
      "Fold 18 accuracy: 1.0\n",
      "Fold 19 accuracy: 0.8888888888888888\n",
      "Fold 20 accuracy: 1.0\n",
      "Fold 21 accuracy: 1.0\n",
      "Fold 22 accuracy: 0.8888888888888888\n",
      "Fold 23 accuracy: 1.0\n",
      "Fold 24 accuracy: 1.0\n",
      "Fold 25 accuracy: 1.0\n",
      "Fold 26 accuracy: 0.9444444444444444\n",
      "Fold 27 accuracy: 1.0\n",
      "Fold 28 accuracy: 1.0\n",
      "Fold 29 accuracy: 0.9444444444444444\n",
      "Fold 30 accuracy: 0.8888888888888888\n",
      "Fold 31 accuracy: 1.0\n",
      "Fold 32 accuracy: 0.9444444444444444\n",
      "Fold 33 accuracy: 1.0\n",
      "Fold 34 accuracy: 0.9444444444444444\n",
      "Fold 35 accuracy: 1.0\n",
      "Fold 36 accuracy: 0.8333333333333334\n",
      "Fold 37 accuracy: 1.0\n",
      "Fold 38 accuracy: 1.0\n",
      "Fold 39 accuracy: 0.9444444444444444\n",
      "Fold 40 accuracy: 0.9444444444444444\n",
      "Fold 41 accuracy: 1.0\n",
      "Fold 42 accuracy: 1.0\n",
      "Fold 43 accuracy: 1.0\n",
      "Fold 44 accuracy: 1.0\n",
      "Fold 45 accuracy: 1.0\n",
      "Fold 46 accuracy: 1.0\n",
      "Fold 47 accuracy: 1.0\n",
      "Fold 48 accuracy: 0.9411764705882353\n",
      "Fold 49 accuracy: 0.8823529411764706\n",
      "Fold 50 accuracy: 1.0\n",
      "Mean Accuracy: 0.9609150326797387\n"
     ]
    }
   ],
   "source": [
    "# Cross validation using 50 folds\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(892, n_folds=50)\n",
    "    outcomes = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf:\n",
    "        fold += 1\n",
    "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n",
    "\n",
    "run_kfold(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    892816\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions and output\n",
    "ids = test_df['id']\n",
    "predictions = clf.predict(test_df.drop('id', axis=1))\n",
    "\n",
    "output = pd.DataFrame({ 'id' : ids, 'target': predictions })\n",
    "output.to_csv('driver-predictions.csv', index = False)\n",
    "output['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight:<br>\n",
    "1. The data target is pretty biased toward 0. <br>\n",
    "2. Classifier seems to be not a good option because it'll magnify the problem of a majority target. As in the example above, even if we have magnified the entries of target 1 with 5 copies, the final prediction number is still all 0. Thus, we'll focus more on regression models in the future"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
