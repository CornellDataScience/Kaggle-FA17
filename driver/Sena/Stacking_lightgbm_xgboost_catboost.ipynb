{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This python script is an ensembler of xgboost, lightgbm and catb\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#...load training and testing data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Drop the id and target parameters in the train/test set \n",
    "id_test = test['id'].values\n",
    "target_train = train['target'].values\n",
    "\n",
    "train = train.drop(['target','id'], axis = 1)\n",
    "test = test.drop(['id'], axis = 1)\n",
    "\n",
    "\n",
    "#Drop the columns that are derived from other columns. These are delimited with _calc_\n",
    "col_to_drop = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "train = train.drop(col_to_drop, axis=1)  \n",
    "test = test.drop(col_to_drop, axis=1)  \n",
    "\n",
    "#\n",
    "train = train.replace(-1, np.nan)\n",
    "test = test.replace(-1, np.nan)\n",
    "\n",
    "\n",
    "cat_features = [a for a in train.columns if a.endswith('cat')]\n",
    "\n",
    "def convertToCategorical(features, data):\n",
    "    \"\"\"\n",
    "    Converts features in a dataset into categorical features\n",
    "    \"\"\"\n",
    "    \n",
    "    for column in features:\n",
    "        temp = pd.get_dummies(pd.Series(data[column]))\n",
    "        data = pd.concat([data,temp],axis=1)\n",
    "        data = data.drop([column],axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "convertToCategorical(cat_features, train)\n",
    "convertToCategorical(cat_features, test) \n",
    "    \n",
    "print(train.values.shape, test.values.shape)\n",
    "\n",
    "\n",
    "\n",
    "class Ensemble(object):\n",
    "    \"\"\"\n",
    "    This class is used to make an ensembler. It is adapted from Kevin Lou python script of Ensemling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns the final probabilities of each Driver id from stacking different models \n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "        results = cross_val_score(self.stacker, S_train, y, cv=3, scoring='roc_auc')\n",
    "        print(\"Stacker score: %.5f\" % (results.mean()))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict_proba(S_test)[:,1]\n",
    "        return res\n",
    "\n",
    "\n",
    "\n",
    "##Specify the parameters for the different models\n",
    "\n",
    "\n",
    "# LightGBM params\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.02\n",
    "lgb_params['n_estimators'] = 650\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['seed'] = 99\n",
    "\n",
    "\n",
    "\n",
    "# XGBoost params\n",
    "xgb_params = {}\n",
    "xgb_params['objective'] = 'binary:logistic'\n",
    "xgb_params['learning_rate'] = 0.04\n",
    "xgb_params['n_estimators'] = 490\n",
    "xgb_params['max_depth'] = 4\n",
    "xgb_params['subsample'] = 0.9\n",
    "xgb_params['colsample_bytree'] = 0.9  \n",
    "xgb_params['min_child_weight'] = 10\n",
    "\n",
    "\n",
    "# CatBoost params\n",
    "cat_params = {}\n",
    "cat_params['iterations'] = 900\n",
    "cat_params['depth'] = 8\n",
    "cat_params['rsm'] = 0.95\n",
    "cat_params['learning_rate'] = 0.03\n",
    "cat_params['l2_leaf_reg'] = 3.5  \n",
    "cat_params['border_count'] = 8\n",
    "cat_params['gradient_iterations'] = 4\n",
    "\n",
    "\n",
    "\n",
    "lgb_model = LGBMClassifier(**lgb_params)\n",
    "        \n",
    "xgb_model = XGBClassifier(**xgb_params)\n",
    "\n",
    "cat_model = CatBoostClassifier(**cat_params)\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "\n",
    "##Make an ensembler of the models        \n",
    "stack = Ensemble(n_splits=3,\n",
    "        stacker = log_model,\n",
    "        base_models = (lgb_model, xgb_model, cat_model))        \n",
    "\n",
    "#predict on the testing set\n",
    "y_pred = stack.fit_predict(train, target_train, test)        \n",
    "\n",
    "\n",
    "#append the id and the predicted data and write to a csv file\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_pred\n",
    "sub.to_csv('stacked_gbm_xgb_catboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
