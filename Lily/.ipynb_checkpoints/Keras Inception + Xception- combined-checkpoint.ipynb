{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:27<00:00, 371.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222/10222 [==============================] - 2184s  \n",
      "10222/10222 [==============================] - 4278s   \n",
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/10\n",
      "9199/9199 [==============================] - 1s - loss: 1.8761 - acc: 0.5978 - val_loss: 0.7030 - val_acc: 0.8074\n",
      "Epoch 2/10\n",
      "9199/9199 [==============================] - 0s - loss: 0.5790 - acc: 0.8386 - val_loss: 0.5535 - val_acc: 0.8368\n",
      "Epoch 3/10\n",
      "9199/9199 [==============================] - 0s - loss: 0.4444 - acc: 0.8716 - val_loss: 0.5106 - val_acc: 0.8446\n",
      "Epoch 4/10\n",
      "9199/9199 [==============================] - 0s - loss: 0.3569 - acc: 0.8961 - val_loss: 0.4930 - val_acc: 0.8485\n",
      "Epoch 5/10\n",
      "9199/9199 [==============================] - 0s - loss: 0.3039 - acc: 0.9154 - val_loss: 0.4642 - val_acc: 0.8563\n",
      "Epoch 6/10\n",
      "9199/9199 [==============================] - 0s - loss: 0.2597 - acc: 0.9311 - val_loss: 0.4686 - val_acc: 0.8534\n",
      "Epoch 7/10\n",
      "9199/9199 [==============================] - 0s - loss: 0.2281 - acc: 0.9369 - val_loss: 0.4662 - val_acc: 0.8641\n",
      "Epoch 8/10\n",
      "9199/9199 [==============================] - 0s - loss: 0.2013 - acc: 0.9448 - val_loss: 0.4610 - val_acc: 0.8524\n",
      "Epoch 9/10\n",
      "9199/9199 [==============================] - 0s - loss: 0.1810 - acc: 0.9499 - val_loss: 0.4638 - val_acc: 0.8543\n",
      "Epoch 10/10\n",
      "9199/9199 [==============================] - 0s - loss: 0.1615 - acc: 0.9600 - val_loss: 0.4587 - val_acc: 0.8573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10357/10357 [00:25<00:00, 401.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10357/10357 [==============================] - 2269s   \n",
      " 7296/10357 [====================>.........] - ETA: 1266s"
     ]
    }
   ],
   "source": [
    "# load data set\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../labels.csv')\n",
    "df.head()\n",
    "n = len(df)\n",
    "breed = set(df['breed'])\n",
    "n_class = len(breed)\n",
    "class_to_num = dict(zip(breed, range(n_class)))\n",
    "num_to_class = dict(zip(range(n_class), breed))\n",
    "width = 299\n",
    "X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, n_class), dtype=np.uint8)\n",
    "for i in tqdm(range(n)):\n",
    "    X[i] = cv2.resize(cv2.imread('../train/%s.jpg' % df['id'][i]), (width, width))\n",
    "    y[i][class_to_num[df['breed'][i]]] = 1\n",
    "    \n",
    "# visualize dataset\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    random_index = random.randint(0, n-1)\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(X[random_index][:,:,::-1])\n",
    "    plt.title(num_to_class[y[random_index].argmax()])\n",
    "    \n",
    "# select features\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "def get_features(MODEL, data=X):\n",
    "    cnn_model = MODEL(include_top=False, input_shape=(width, width, 3), weights='imagenet')\n",
    "    \n",
    "    inputs = Input((width, width, 3))\n",
    "    x = inputs\n",
    "    x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "    x = cnn_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    cnn_model = Model(inputs, x)\n",
    "\n",
    "    features = cnn_model.predict(data, batch_size=64, verbose=1)\n",
    "    return features\n",
    "inception_features = get_features(InceptionV3, X)\n",
    "xception_features = get_features(Xception, X)\n",
    "features = np.concatenate([inception_features, xception_features], axis=-1)\n",
    "\n",
    "# train the model\n",
    "inputs = Input(features.shape[1:])\n",
    "x = inputs\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax')(x)\n",
    "model = Model(inputs, x)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "h = model.fit(features, y, batch_size=128, epochs=10, validation_split=0.1)\n",
    "\n",
    "# visualize training process\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.legend(['acc', 'val_acc'])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "# load test set\n",
    "df2 = pd.read_csv('../sample_submission.csv')\n",
    "n_test = len(df2)\n",
    "X_test = np.zeros((n_test, width, width, 3), dtype=np.uint8)\n",
    "for i in tqdm(range(n_test)):\n",
    "    X_test[i] = cv2.resize(cv2.imread('../test/%s.jpg' % df2['id'][i]), (width, width))\n",
    "    \n",
    "# select test featuers\n",
    "inception_features = get_features(InceptionV3, X_test)\n",
    "xception_features = get_features(Xception, X_test)\n",
    "features_test = np.concatenate([inception_features, xception_features], axis=-1)\n",
    "\n",
    "# predict and save prediction\n",
    "y_pred = model.predict(features_test, batch_size=128)\n",
    "for b in breed:\n",
    "    df2[b] = y_pred[:,class_to_num[b]]\n",
    "df2.to_csv('../pred.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
