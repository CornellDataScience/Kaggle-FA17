{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module '_catboost' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hyperopt\n",
    "from catboost import Pool, CatBoostRegressor, cv, CatboostIpythonWidget\n",
    "#Note does not include latest batch of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_2016 = pd.read_csv('../datasets/train_2016_v2.csv', parse_dates=['transactiondate'])\n",
    "train_2017 = pd.read_csv('../datasets/train_2017.csv', parse_dates=['transactiondate'])\n",
    "properties_2016 = pd.read_csv('../datasets/properties_2016.csv')\n",
    "properties_2017 = pd.read_csv('../datasets/properties_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_date_features(df):\n",
    "    df[\"transaction_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transaction_month\"] = df[\"transactiondate\"].dt.month\n",
    "    df[\"transaction_quarter\"] = df[\"transactiondate\"].dt.quarter\n",
    "    df.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_2016 = add_date_features(train_2016)\n",
    "train_2017 = add_date_features(train_2017)\n",
    "train_2016 = train_2016.merge(properties_2016, how='left', on='parcelid')\n",
    "train_2017 = train_2017.merge(properties_2017, how='left', on='parcelid')\n",
    "train_df = train_2016.append(train_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_perc_thresh = 0.98\n",
    "exclude_missing = []\n",
    "num_rows = train_df.shape[0]\n",
    "for c in train_df.columns:\n",
    "    num_missing = train_df[c].isnull().sum()\n",
    "    if num_missing == 0:\n",
    "        continue\n",
    "    missing_frac = num_missing / float(num_rows)\n",
    "    if missing_frac > missing_perc_thresh:\n",
    "        exclude_missing.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude_unique = []\n",
    "for c in train_df.columns:\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if train_df[c].isnull().sum() != 0:\n",
    "        num_uniques -= 1\n",
    "    if num_uniques == 1:\n",
    "        exclude_unique.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude_other = ['parcelid', 'logerror']  # for indexing/training only\n",
    "# do not know what this is LARS, 'SHCG' 'COR2YY' 'LNR2RPD-R3' ?!?\n",
    "exclude_other.append('propertyzoningdesc')\n",
    "train_features = []\n",
    "for c in train_df.columns:\n",
    "    if c not in exclude_missing \\\n",
    "       and c not in exclude_other and c not in exclude_unique:\n",
    "        train_features.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_feature_inds = []\n",
    "cat_unique_thresh = 1000\n",
    "for i, c in enumerate(train_features):\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if num_uniques < cat_unique_thresh \\\n",
    "       and not 'sqft' in c \\\n",
    "       and not 'cnt' in c \\\n",
    "       and not 'nbr' in c \\\n",
    "       and not 'number' in c:\n",
    "        cat_feature_inds.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyperopt_objective(params):\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        l2_leaf_reg=int(params['l2_leaf_reg']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        bagging_temperature=params['bagging_temperature'],\n",
    "        rsm=params['rsm'],\n",
    "        depth=params['depth'],\n",
    "        border_count=params['border_count'],\n",
    "        ctr_border_count=params['ctr_border_count'],\n",
    "        iterations=200,\n",
    "        eval_metric='MAE',\n",
    "        loss_function='MAE'\n",
    "    )\n",
    "    cv_data = cv(\n",
    "        model.get_params(),\n",
    "        Pool(train_df[train_features], train_df['logerror'], cat_features=cat_feature_inds)\n",
    "    )\n",
    "    return np.min(cv_data['b\\'MAE\\'_test_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/catboost/core.py:1304: UserWarning: Parameter \"use_best_model\" has no effect in cross-validation and is ignored\n",
      "  warnings.warn('Parameter \"use_best_model\" has no effect in cross-validation and is ignored')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_temperature': 0.7218369037954099, 'border_count': 246, 'ctr_border_count': 197, 'depth': 7, 'l2_leaf_reg': 4.0, 'learning_rate': 0.030747575306233767, 'rsm': 0.8506573951709594}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from itertools import combinations\n",
    "\n",
    "params_space = {\n",
    "    'l2_leaf_reg': hyperopt.hp.qloguniform('l2_leaf_reg', 0, 2, 1),\n",
    "    'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-3, 5e-1),\n",
    "    'bagging_temperature': hyperopt.hp.uniform('bagging_temperature', 0, 1),\n",
    "    'depth': hyperopt.hp.choice('depth', np.arange(1, 11, dtype=int)),\n",
    "    'rsm': hyperopt.hp.uniform('rsm', 0, 1),\n",
    "    'border_count': hyperopt.hp.choice('border_count', np.arange(1, 256, dtype=int)),\n",
    "    'ctr_border_count': hyperopt.hp.choice('ctr_border_count', np.arange(1, 256, dtype=int))\n",
    "}\n",
    "best = hyperopt.fmin(\n",
    "    hyperopt_objective,\n",
    "    space=params_space,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=55\n",
    ")\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/catboost/core.py:1304: UserWarning: Parameter \"use_best_model\" has no effect in cross-validation and is ignored\n",
      "  warnings.warn('Parameter \"use_best_model\" has no effect in cross-validation and is ignored')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1\n"
     ]
    }
   ],
   "source": [
    "#training on entire ensemble impractical, much too long to run anything\n",
    "%%timeit\n",
    "num_ensembles=5\n",
    "accuracy=0.0\n",
    "for i in range(num_ensembles):\n",
    "    # TODO(you): Use CV, tune hyperparameters\n",
    "    print('Training ' + str(i))\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=200,\n",
    "        eval_metric='MAE',\n",
    "        loss_function='MAE',\n",
    "        random_seed=1\n",
    "    )\n",
    "    cv_data = cv(\n",
    "        model.get_params(),\n",
    "        Pool(train_df[train_features], train_df['logerror'], cat_features=cat_feature_inds)\n",
    "    )\n",
    "    accuracy += np.min(cv_data['b\\'MAE\\'_test_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
