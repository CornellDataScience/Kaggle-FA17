{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train Shape: \n",
      "(164299, 51)\n",
      "Y train Shape: \n",
      "(164299,)\n",
      "['transaction_year', 'transaction_month', 'transaction_quarter', 'sin_month', 'cos_month', 'sin_quarter', 'cos_quarter', 'airconditioningtypeid', 'bathroomcnt', 'bedroomcnt', 'buildingqualitytypeid', 'calculatedbathnbr', 'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'finishedsquarefeet15', 'finishedsquarefeet50', 'fips', 'fireplacecnt', 'fullbathcnt', 'garagecarcnt', 'garagetotalsqft', 'heatingorsystemtypeid', 'latitude', 'longitude', 'lotsizesquarefeet', 'propertycountylandusecode', 'propertylandusetypeid', 'rawcensustractandblock', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'roomcnt', 'threequarterbathnbr', 'unitcnt', 'yardbuildingsqft17', 'yearbuilt', 'numberofstories', 'structuretaxvaluedollarcnt', 'taxvaluedollarcnt', 'assessmentyear', 'landtaxvaluedollarcnt', 'taxamount', 'taxdelinquencyyear', 'censustractandblock', 'x', 'y', 'z', 'latlong_pca0', 'latlong_pca1']\n",
      "Cat features are: ['transaction_year', 'transaction_month', 'transaction_quarter', 'airconditioningtypeid', 'buildingqualitytypeid', 'fips', 'heatingorsystemtypeid', 'propertycountylandusecode', 'propertylandusetypeid', 'rawcensustractandblock', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'yearbuilt', 'assessmentyear', 'taxdelinquencyyear', 'censustractandblock']\n",
      "adding baseline models to ensembler\n",
      "training ensembler\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-37bfe92a4262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training ensembler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;31m######################################### PREDICTING ON ENSEMBLE #######################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlens/ensemble/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, return_preds, **process_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Fit ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlens/parallel/manager.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0;31m# Process layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0;31m# Update input array with output array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlens/parallel/manager.py\u001b[0m in \u001b[0;36m_partial_process\u001b[0;34m(self, name, lyr, parallel)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mkwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlyr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_kwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlyr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_kwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENGINES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlyr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlyr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mengine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# Propagate features from input to output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlens/parallel/estimation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, parallel)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlens/parallel/stack.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parallel)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;34m\"\"\"Execute stacking.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStacker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_instance_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlens/parallel/estimation.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parallel)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_initialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlens/parallel/_base_functions.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(inst, X, y, P, dir, parallel)\u001b[0m\n\u001b[1;32m     71\u001b[0m                               \u001b[0mattr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                               scorer=inst.layer.scorer)\n\u001b[0;32m---> 73\u001b[0;31m              \u001b[0;32mfor\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtei\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m              for inst_name, instance in instance_list)\n\u001b[1;32m     75\u001b[0m     \u001b[0massemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mlens/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "from mlens.preprocessing import EnsembleTransformer\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.model_selection import Evaluator\n",
    "from sklearn.base import BaseEstimator\n",
    "from model_super import *\n",
    "from models import *\n",
    "from ensembler import *\n",
    "from parameters import *\n",
    "from data_processing import *\n",
    "from gridSearch import *\n",
    "import os.path as path\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO:  Analyze different base models with gridsearch (RandomForest, Adaboost, Neural Networks, DecisionTree, Lasso)\n",
    "# TODO:  remember to scale neural network training data before feeding it\n",
    "\n",
    "############################################## Custom Classes #########################################################\n",
    "\n",
    "class MultiCatBoost(BaseEstimator):\n",
    "\n",
    "    def __init__(self, parameters, cat_feature_inds):\n",
    "        self.cat_feature_inds = cat_feature_inds\n",
    "        self.models = []\n",
    "        self.parameters = parameters\n",
    "        for i in range(5):\n",
    "            self.models.append(CatBoostRegressor(**self.parameters, random_seed=i))\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        for i in range(5):\n",
    "            self.models[i].fit(x_train, y_train, cat_features=self.cat_feature_inds)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        result = 0.0\n",
    "        for model in self.models:\n",
    "            print(\"predicting on catboost\")\n",
    "            result += model.predict(x_test, verbose=True)\n",
    "        result /= 5\n",
    "        return result\n",
    "\n",
    "\n",
    "class MultiXGBoost(BaseEstimator):\n",
    "\n",
    "    def __init__(self, parameters):\n",
    "        self.models = []\n",
    "        self.parameters = parameters\n",
    "        for i in range(5):\n",
    "            self.models.append(XGBRegressor(**self.parameters, random_state=i))\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        for i in range(5):\n",
    "            self.models[i].fit(x_train, y_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        result = 0.0\n",
    "        for model in self.models:\n",
    "            print(\"predicting on xgboost\")\n",
    "            result += model.predict(x_test)\n",
    "        result /= 5\n",
    "        return result\n",
    "\n",
    "\n",
    "class MultiLightGBM(BaseEstimator):\n",
    "\n",
    "    def __init__(self, parameters):\n",
    "        self.models = []\n",
    "        self.parameters = parameters\n",
    "        for i in range(5):\n",
    "            self.models.append(LGBMRegressor(**self.parameters, random_state=i))\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        for i in range(5):\n",
    "            self.models[i].fit(x_train, y_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        result = 0.0\n",
    "        for model in self.models:\n",
    "            print(\"predicting on lightgbm\")\n",
    "            result += model.predict(x_test)\n",
    "        result /= 5\n",
    "        return result\n",
    "\n",
    "############################################## Helper methods ##########################################################\n",
    "\n",
    "#Performs gridsearch on the \"meta-learners\" which predict on the first layer predictions\n",
    "def evaluateSecondLayer(base_learners, x_train, y_train, meta_learners, param_dicts):\n",
    "    in_layer = EnsembleTransformer()\n",
    "    print(\"adding base learners to transformer\")\n",
    "    in_layer.add('stack', base_learners)\n",
    "\n",
    "    preprocess = [in_layer]\n",
    "    print(\"creating scorer\")\n",
    "    scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    evl = Evaluator(scorer, cv=4, verbose=1)\n",
    "    print(\"fitting evaluator\")\n",
    "    evl.fit(x_train.values,\n",
    "        y_train.values,\n",
    "        meta_learners,\n",
    "        param_dicts,\n",
    "        preprocessing={'meta': preprocess},\n",
    "        n_iter=30                            # bump this up to do a larger grid search\n",
    "       )\n",
    "\n",
    "    table = pd.DataFrame(evl.summary)\n",
    "    table.to_html('HyperCatboost.html')\n",
    "    table.to_csv('HypterCatboost.csv', index=False, header=False, sep='\\t')\n",
    "\n",
    "\n",
    "#Adds features to the dataset\n",
    "def add_date_features(df):\n",
    "    df[\"transaction_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transaction_month\"] = df[\"transactiondate\"].dt.month\n",
    "    df[\"transaction_quarter\"] = df[\"transactiondate\"].dt.quarter\n",
    "    df['sin_month'] = np.sin(df['transaction_month'] * np.pi/12)\n",
    "    df['cos_month'] = np.sin(df['transaction_month'] * np.pi/12)\n",
    "    df['sin_quarter'] = np.sin(df['transaction_quarter'] * np.pi/4)\n",
    "    df['cos_quarter'] = np.sin(df['transaction_quarter'] * np.pi/4)\n",
    "    df.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "def add_geographic_features(property2016, property2017):\n",
    "    property2016['year'] = 2016\n",
    "    property2017['year'] = 2017\n",
    "    complete = property2016.append(property2017)\n",
    "    radian_lat = complete['latitude'] * np.pi/180\n",
    "    radian_long = complete['longitude'] * np.pi/180\n",
    "    earth_radius = 3959\n",
    "    complete['x'] = (-earth_radius * np.cos(radian_lat) * np.sin(radian_long)).fillna(-1)\n",
    "    complete['y'] = (earth_radius * np.sin(radian_lat)).fillna(-1)\n",
    "    complete['z'] = (earth_radius * np.cos(radian_lat) * np.sin(radian_long)).fillna(-1)\n",
    "    pca = PCA(n_components=2)\n",
    "    rotated_latlong = pca.fit_transform(complete[['latitude', 'longitude']].fillna(-1))\n",
    "    complete['latlong_pca0'] = rotated_latlong[:,0]\n",
    "    complete['latlong_pca1'] = rotated_latlong[:,1]\n",
    "    dropcols = ['year']\n",
    "    return complete[complete.year == 2016].drop(dropcols, axis=1), complete[complete.year == 2017].drop(dropcols, axis=1)\n",
    "\n",
    "def generate_first_layer_predictions():\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    kf = KFold(n_splits=4)\n",
    "    folds = list(kf.split(x_train, y_train))\n",
    "\n",
    "    first_layer_train_predictions = np.zeros((x_train.shape[0], len(models)))\n",
    "\n",
    "    #train first layer\n",
    "    for i in range(len(models)):\n",
    "        print(\"training baseline model\")\n",
    "        for j, (train_idx, test_idx) in enumerate(folds):\n",
    "            x_train_fold = x_train[train_idx]\n",
    "            y_train_fold = y_train[train_idx]\n",
    "            x_holdout_fold = x_train[test_idx]\n",
    "            y_holdout_fold = y_train[test_idx]\n",
    "            models[i].fit(x_train_fold, y_train_fold)\n",
    "            first_layer_train_predictions[test_idx, i] = models[i].predict(x_holdout_fold)\n",
    "\n",
    "    print(\"first layer train predictions: \")\n",
    "    print(first_layer_train_predictions)\n",
    "    print(\"shape: \")\n",
    "    print(first_layer_train_predictions.shape)\n",
    "    print(\"building csv\")\n",
    "    np.savetxt(\"predictions_first_layer.csv\", first_layer_train_predictions, delimiter=\",\")\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, x_train, y_train):\n",
    "    title = \"XGBoost as Second Layer Predictor\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    print(\"calculating learning curve values\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, x_train, y_train, n_jobs=-1, \n",
    "                scoring = 'neg_mean_absolute_error', cv=4)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    print('showing plot')\n",
    "    plt.show()\n",
    "    print(test_scores_mean)\n",
    "\n",
    "def plot_validation_curve(estimator, x_train, y_train, param_name, param_range):\n",
    "    print('computing validation curve values')\n",
    "    train_scores, test_scores = validation_curve(estimator, x_train, y_train, param_name=param_name, \n",
    "                param_range=param_range, scoring='neg_mean_absolute_error', n_jobs=-1, cv=4)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.title(\"XGBoost colsample analysis\")\n",
    "    plt.xlabel(\"colsample\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    lw = 2\n",
    "    plt.plot(param_range, train_scores_mean, 'r+', label='Train')\n",
    "    plt.plot(param_range, test_scores_mean, 'g+', label='Test')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(test_scores_mean)\n",
    "\n",
    "########################################### LOADING DATA ##############################################################\n",
    "\n",
    "dir_path = path.abspath(path.join('__file__',\"../../..\"))\n",
    "\n",
    "train_path = dir_path + '/training_data_custom.csv'\n",
    "test_2016_path = dir_path + '/test_2016_data_custom.csv'\n",
    "test_2017_path = dir_path + '/test_2017_data_custom.csv'\n",
    "\n",
    "#Load Train Data\n",
    "train_data = pd.read_csv(train_path)\n",
    "x_train = train_data.drop('logerror', 1)\n",
    "y_train = train_data.logerror\n",
    "\n",
    "#Identify categorical columns for catboost\n",
    "train_features = list(x_train)\n",
    "cat_feature_inds = categoricalColumns(x_train, train_features)\n",
    "\n",
    "#Load Test Data\n",
    "X_test_2016 = pd.read_csv(test_2016_path)\n",
    "X_test_2017 = pd.read_csv(test_2017_path)\n",
    "  \n",
    "\n",
    "#x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=27000)\n",
    "\n",
    "############################################# Graph Learning Curve ####################################################\n",
    "\n",
    "#estimator = Ridge(**ridge_params)\n",
    "#estimator = XGBRegressor(**xgb_params_2)\n",
    "#plot_learning_curve(estimator, first_layer_results, y_train)\n",
    "\n",
    "############################################ Graph Validation Curve ###################################################\n",
    "\n",
    "#value_range = [2, 3, 4, 5]\n",
    "#plot_validation_curve(estimator, first_layer_results, y_train,'max_depth', value_range)\n",
    "\n",
    "########################################## Create and Train Ensembler ##################################################\n",
    "\n",
    "\n",
    "ensemble = SuperLearner(folds=4)\n",
    "\n",
    "print(\"adding baseline models to ensembler\")\n",
    "\n",
    "ensemble.add([MultiXGBoost(getXGBParams(y_train)), MultiLightGBM(lightGBM_params),\n",
    "              MultiCatBoost(catboost_params, cat_feature_inds)])\n",
    "\n",
    "#ensemble.add_meta(XGBRegressor(**xgb_params_2))\n",
    "ensemble.add_meta(Ridge(**ridge_params))\n",
    "\n",
    "print(\"training ensembler\")\n",
    "ensemble.fit(x_train, y_train)\n",
    "\n",
    "######################################### PREDICTING ON ENSEMBLE #######################################################\n",
    "\n",
    "print(\"predicting on ensembler\")\n",
    "preds = ensemble.predict(X_test)\n",
    "\n",
    "\n",
    "\"\"\"\"#Validation prediction:\n",
    "\n",
    "preds = ensemble.predict(x_val)\n",
    "accuracy = mean_absolute_error(y_val, preds)\n",
    "print('validation accuracy: ')\n",
    "print(accuracy) \"\"\"\n",
    "\n",
    "######################################### BUILDING KAGGLE SUBMISSION ###################################################\n",
    "\n",
    "\n",
    "print(\"building prediction submission: \")\n",
    "sub = pd.read_csv(test_path)\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = preds\n",
    "\n",
    "print('Writing csv ...')\n",
    "sub.to_csv('kaggle_submission.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
