{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #linalg\n",
    "import pandas as pd #IO\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from shutil import copy2\n",
    "\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "#Using TensorFlow \n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG19 is slower but more accurate than VGG16\n",
    "from keras.applications.vgg19 import VGG19 \n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading Files\n",
      "\n",
      "Formatting Data and Submission Type\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nReading Files\")\n",
    "df_train = pd.read_csv('../labels.csv')\n",
    "df_test = pd.read_csv('../sample_submission.csv')\n",
    "\n",
    "#Format data into sample submission format\n",
    "print(\"\\nFormatting Data and Submission Type\")\n",
    "targets_series = pd.Series(df_train['breed'])\n",
    "one_hot = pd.get_dummies(targets_series, sparse = True)\n",
    "one_hot_labels = np.asarray(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/10222 [00:00<00:29, 345.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Training Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:24<00:00, 415.70it/s]\n",
      "100%|██████████| 10357/10357 [00:24<00:00, 424.88it/s]\n"
     ]
    }
   ],
   "source": [
    "#Set the Image Rescale size\n",
    "print(\"\\nBuilding Training Test...\")\n",
    "im_size = 224\n",
    "\n",
    "#Build the training arrays\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "\n",
    "i = 0 \n",
    "for f, breed in tqdm(df_train.values):\n",
    "    img = cv2.imread('../train/{}.jpg'.format(f))\n",
    "    label = one_hot_labels[i]\n",
    "    x_train.append(cv2.resize(img, (im_size, im_size)))\n",
    "    y_train.append(label)\n",
    "    i += 1\n",
    "    \n",
    "for f in tqdm(df_test['id'].values):\n",
    "    img = cv2.imread('../test/{}.jpg'.format(f))\n",
    "    x_test.append(cv2.resize(img, (im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(filedir):\n",
    "    im = cv2.resize(cv2.imread(filedir), (224, 224)).astype(np.float32)\n",
    "    im = im.transpose((2,0,1))\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Training Test...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBuilding Training Test...\")\n",
    "im_size = 224\n",
    "\n",
    "#Build the training arrays\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0 \n",
    "for f, breed in tqdm(df_train.values):\n",
    "    filedir = '../train/{}.jpg'.format(f)\n",
    "    label = one_hot_labels[i]\n",
    "    x_train.append(resize_image(filedir))\n",
    "    y_train.append(label)\n",
    "    i += 1\n",
    "    \n",
    "for f in tqdm(df_test['id'].values):\n",
    "    filedir = cv2.imread'../test/{}.jpg'.format(f))\n",
    "    x_test.append(cv2.resize(img, (im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Done\n"
     ]
    }
   ],
   "source": [
    "num_class = y_train_raw.shape[1]\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train_raw, y_train_raw, test_size=0.3, random_state=1)\n",
    "\n",
    "print(\"\\n Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building Model...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nBuilding Model...\")\n",
    "\n",
    "base_model = VGG19(weights='imagenet',include_top=False, input_shape=(im_size, im_size, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 90, 90, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 90, 90, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 90, 90, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 45, 45, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 45, 45, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 22, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 22, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 22, 22, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 11, 11, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 20,270,264\n",
      "Trainable params: 245,880\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/20\n",
      "7155/7155 [==============================] - 581s - loss: 4.6044 - acc: 0.0503 - val_loss: 4.3209 - val_acc: 0.0756\n",
      "Epoch 2/20\n",
      "7155/7155 [==============================] - 596s - loss: 3.6244 - acc: 0.1897 - val_loss: 4.1299 - val_acc: 0.1034\n",
      "Epoch 3/20\n",
      "7155/7155 [==============================] - 791s - loss: 3.1124 - acc: 0.2959 - val_loss: 4.0400 - val_acc: 0.1206\n",
      "Epoch 4/20\n",
      "7155/7155 [==============================] - 805s - loss: 2.7350 - acc: 0.3895 - val_loss: 4.0170 - val_acc: 0.1301\n",
      "Epoch 5/20\n",
      "7155/7155 [==============================] - 792s - loss: 2.4427 - acc: 0.4553 - val_loss: 3.9868 - val_acc: 0.1356\n",
      "Epoch 6/20\n",
      "7155/7155 [==============================] - 769s - loss: 2.1980 - acc: 0.5276 - val_loss: 3.9915 - val_acc: 0.1396\n",
      "Epoch 7/20\n",
      "7155/7155 [==============================] - 762s - loss: 1.9920 - acc: 0.5796 - val_loss: 4.0093 - val_acc: 0.1493\n",
      "Epoch 8/20\n",
      "7155/7155 [==============================] - 763s - loss: 1.7946 - acc: 0.6423 - val_loss: 4.0513 - val_acc: 0.1399\n",
      "Epoch 9/20\n",
      "7155/7155 [==============================] - 762s - loss: 1.6448 - acc: 0.6753 - val_loss: 4.0815 - val_acc: 0.1386\n",
      "Epoch 10/20\n",
      "7155/7155 [==============================] - 761s - loss: 1.4992 - acc: 0.7166 - val_loss: 4.0977 - val_acc: 0.1389\n",
      "Epoch 11/20\n",
      "7155/7155 [==============================] - 763s - loss: 1.3729 - acc: 0.7528 - val_loss: 4.1262 - val_acc: 0.1399\n",
      "Epoch 12/20\n",
      "7155/7155 [==============================] - 762s - loss: 1.2608 - acc: 0.7816 - val_loss: 4.1676 - val_acc: 0.1405\n",
      "Epoch 13/20\n",
      "7155/7155 [==============================] - 762s - loss: 1.1516 - acc: 0.8144 - val_loss: 4.1788 - val_acc: 0.1418\n",
      "Epoch 14/20\n",
      "7155/7155 [==============================] - 761s - loss: 1.0627 - acc: 0.8373 - val_loss: 4.2320 - val_acc: 0.1343\n",
      "Epoch 15/20\n",
      "7155/7155 [==============================] - 771s - loss: 0.9731 - acc: 0.8590 - val_loss: 4.2616 - val_acc: 0.1379\n",
      "Epoch 16/20\n",
      "7155/7155 [==============================] - 614s - loss: 0.8856 - acc: 0.8833 - val_loss: 4.2984 - val_acc: 0.1353\n",
      "Epoch 17/20\n",
      "7155/7155 [==============================] - 582s - loss: 0.8222 - acc: 0.8943 - val_loss: 4.3466 - val_acc: 0.1386\n",
      "Epoch 18/20\n",
      "7155/7155 [==============================] - 582s - loss: 0.7533 - acc: 0.9128 - val_loss: 4.3841 - val_acc: 0.1392\n",
      "Epoch 19/20\n",
      "7155/7155 [==============================] - 582s - loss: 0.6941 - acc: 0.9233 - val_loss: 4.4246 - val_acc: 0.1340\n",
      "Epoch 20/20\n",
      "7155/7155 [==============================] - 581s - loss: 0.6363 - acc: 0.9354 - val_loss: 4.4723 - val_acc: 0.1373\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Model...\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=100, validation_data=(X_valid, Y_valid), verbose=1)\n",
    "print(\"\\nDone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "10357/10357 [==============================] - 588s   \n",
      "\n",
      " Printing to Disk\n",
      "Prediction_Dog_Classif_20171019043253413827.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPredicting\")\n",
    "preds = model.predict(x_test, verbose=1)\n",
    "sub = pd.DataFrame(preds)\n",
    "\n",
    "# Set column names to those generated by the one-hot encoding earlier\n",
    "col_names = one_hot.columns.values\n",
    "sub.columns = col_names\n",
    "# Insert the column id from the sample_submission at the start of the data frame\n",
    "sub.insert(0, 'id', df_test['id'])\n",
    "sub.head(5)\n",
    "\n",
    "# Write to file\n",
    "print(\"\\n Printing to Disk\")\n",
    "\n",
    "filename = \"Prediction_Dog_Classif_\" + re.sub(\"[^0-9]\", \"\",str(datetime.datetime.now())) + '.csv'\n",
    "print(filename)\n",
    "sub.to_csv(filename,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
